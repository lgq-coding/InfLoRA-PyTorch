{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMmvAGNRLwRg",
        "outputId": "6cdff14c-de84-4763-d789-12cad248f842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec 18 00:16:39 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "torch: 2.9.0+cu126 cuda: 12.6\n",
            "torchvision: 0.24.0+cu126\n"
          ]
        }
      ],
      "source": [
        "# 查看 GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# 查看预装 torch / torchvision 版本 (我们不改动它们)\n",
        "import torch, torchvision, sys\n",
        "print(\"torch:\", torch.__version__, \"cuda:\", torch.version.cuda)\n",
        "print(\"torchvision:\", torchvision.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 克隆 InfLoRA 官方代码\n",
        "!git clone https://github.com/liangyanshuo/InfLoRA.git\n",
        "%cd InfLoRA\n",
        "!ls -la\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYBmLMvbMMy0",
        "outputId": "32f8643e-72b3-4b9e-8b82-c7c07c38151e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'InfLoRA'...\n",
            "remote: Enumerating objects: 343, done.\u001b[K\n",
            "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 343 (delta 110), reused 87 (delta 87), pack-reused 198 (from 1)\u001b[K\n",
            "Receiving objects: 100% (343/343), 7.83 MiB | 11.46 MiB/s, done.\n",
            "Resolving deltas: 100% (157/157), done.\n",
            "/content/InfLoRA\n",
            "total 236\n",
            "drwxr-xr-x 10 root root   4096 Dec 18 00:17 .\n",
            "drwxr-xr-x  1 root root   4096 Dec 18 00:17 ..\n",
            "drwxr-xr-x  2 root root   4096 Dec 18 00:17 configs\n",
            "drwxr-xr-x  3 root root   4096 Dec 18 00:17 dataloaders\n",
            "-rw-r--r--  1 root root  14388 Dec 18 00:17 environment.yaml\n",
            "drwxr-xr-x  8 root root   4096 Dec 18 00:17 .git\n",
            "-rw-r--r--  1 root root 161334 Dec 18 00:17 InfLoRA.png\n",
            "-rw-r--r--  1 root root   1068 Dec 18 00:17 LICENSE\n",
            "drwxr-xr-x  4 root root   4096 Dec 18 00:17 logs\n",
            "-rw-r--r--  1 root root    895 Dec 18 00:17 main.py\n",
            "drwxr-xr-x  3 root root   4096 Dec 18 00:17 methods\n",
            "drwxr-xr-x  4 root root   4096 Dec 18 00:17 models\n",
            "drwxr-xr-x  2 root root   4096 Dec 18 00:17 __pycache__\n",
            "-rw-r--r--  1 root root   4592 Dec 18 00:17 README.md\n",
            "-rw-r--r--  1 root root   4007 Dec 18 00:17 trainer.py\n",
            "drwxr-xr-x  5 root root   4096 Dec 18 00:17 utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 安装其它依赖（不安装 torch/torchvision）\n",
        "!pip install -r requirements.txt 2>/dev/null || true\n",
        "\n",
        "# 如果 repo 没有 requirements.txt，安装常见依赖：\n",
        "!pip install timm==0.6.7 ftfy regex lmdb tqdm tensorboard\n",
        "\n",
        "# 安装其它可能需要的小工具（如果 repo 在 utils 里调用）\n",
        "!pip install einops\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTSId29GMSgt",
        "outputId": "14e4aca1-9028-42e6-8ac0-ac097a076d4d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm==0.6.7\n",
            "  Downloading timm-0.6.7-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (2025.11.3)\n",
            "Collecting lmdb\n",
            "  Downloading lmdb-1.7.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.12/dist-packages (from timm==0.6.7) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm==0.6.7) (0.24.0+cu126)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.14)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.4)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.6.7) (3.5.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm==0.6.7) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.4->timm==0.6.7) (1.3.0)\n",
            "Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.0/510.0 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lmdb-1.7.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (299 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.4/299.4 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lmdb, ftfy, timm\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.22\n",
            "    Uninstalling timm-1.0.22:\n",
            "      Successfully uninstalled timm-1.0.22\n",
            "Successfully installed ftfy-6.3.1 lmdb-1.7.5 timm-0.6.7\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 创建存档路径（示例）\n",
        "!mkdir -p /content/drive/MyDrive/inflora_logs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCKAE2ZfMdC9",
        "outputId": "a438076f-7a29-47f0-e1bb-6b643f4218bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# 确认 data 目录\n",
        "!ls -la data || mkdir -p data && ls -la data\n",
        "\n",
        "# 测试用 torchvision 下载 CIFAR100（如果 repo 自带自动下载可以跳过）\n",
        "python - <<'PY'\n",
        "from torchvision import datasets, transforms\n",
        "datasets.CIFAR100(root='data', download=True)\n",
        "print(\"CIFAR100 downloaded to data/\")\n",
        "PY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMWg7aw0NCqk",
        "outputId": "34257267-df8f-4613-dd0b-1d3655cbfae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "drwxr-xr-x  2 root root 4096 Dec 14 06:30 .\n",
            "drwxr-xr-x 11 root root 4096 Dec 14 06:30 ..\n",
            "CIFAR100 downloaded to data/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bash: line 2: !ls: command not found\n",
            "\r  0%|          | 0.00/169M [00:00<?, ?B/s]\r  0%|          | 32.8k/169M [00:00<18:33, 152kB/s]\r  0%|          | 65.5k/169M [00:00<18:37, 151kB/s]\r  0%|          | 98.3k/169M [00:00<18:31, 152kB/s]\r  0%|          | 229k/169M [00:00<08:31, 330kB/s] \r  0%|          | 459k/169M [00:01<04:44, 593kB/s]\r  1%|          | 918k/169M [00:01<02:30, 1.12MB/s]\r  1%|          | 1.84M/169M [00:01<01:18, 2.14MB/s]\r  2%|▏         | 3.70M/169M [00:01<00:39, 4.21MB/s]\r  4%|▍         | 6.91M/169M [00:01<00:21, 7.44MB/s]\r  6%|▌         | 10.1M/169M [00:02<00:16, 9.61MB/s]\r  8%|▊         | 13.2M/169M [00:02<00:14, 10.9MB/s]\r 10%|▉         | 16.4M/169M [00:02<00:12, 12.0MB/s]\r 12%|█▏        | 19.7M/169M [00:02<00:11, 12.9MB/s]\r 14%|█▎        | 22.9M/169M [00:03<00:10, 13.3MB/s]\r 15%|█▌        | 26.2M/169M [00:03<00:10, 13.7MB/s]\r 17%|█▋        | 29.3M/169M [00:03<00:10, 13.9MB/s]\r 19%|█▉        | 32.5M/169M [00:03<00:09, 14.1MB/s]\r 21%|██        | 35.6M/169M [00:03<00:09, 14.1MB/s]\r 23%|██▎       | 38.7M/169M [00:04<00:09, 14.1MB/s]\r 25%|██▍       | 41.9M/169M [00:04<00:08, 14.2MB/s]\r 27%|██▋       | 45.0M/169M [00:04<00:08, 14.2MB/s]\r 29%|██▊       | 48.2M/169M [00:04<00:08, 14.1MB/s]\r 30%|███       | 51.1M/169M [00:05<00:08, 13.8MB/s]\r 32%|███▏      | 54.2M/169M [00:05<00:08, 13.9MB/s]\r 34%|███▍      | 57.4M/169M [00:05<00:07, 14.0MB/s]\r 36%|███▌      | 60.6M/169M [00:05<00:07, 14.0MB/s]\r 38%|███▊      | 63.6M/169M [00:05<00:07, 13.8MB/s]\r 39%|███▉      | 66.5M/169M [00:06<00:07, 13.6MB/s]\r 41%|████      | 69.3M/169M [00:06<00:07, 13.4MB/s]\r 43%|████▎     | 72.4M/169M [00:06<00:07, 13.6MB/s]\r 45%|████▍     | 75.4M/169M [00:06<00:06, 13.5MB/s]\r 46%|████▋     | 78.2M/169M [00:07<00:06, 13.3MB/s]\r 48%|████▊     | 81.0M/169M [00:07<00:05, 15.6MB/s]\r 49%|████▉     | 82.7M/169M [00:07<00:06, 13.9MB/s]\r 50%|████▉     | 84.3M/169M [00:07<00:06, 12.5MB/s]\r 51%|█████▏    | 86.9M/169M [00:07<00:06, 12.4MB/s]\r 53%|█████▎    | 89.7M/169M [00:07<00:06, 12.6MB/s]\r 55%|█████▍    | 92.5M/169M [00:08<00:05, 15.3MB/s]\r 56%|█████▌    | 94.2M/169M [00:08<00:05, 13.5MB/s]\r 57%|█████▋    | 95.7M/169M [00:08<00:05, 12.3MB/s]\r 58%|█████▊    | 98.4M/169M [00:08<00:05, 12.4MB/s]\r 60%|█████▉    | 101M/169M [00:08<00:05, 12.7MB/s] \r 62%|██████▏   | 104M/169M [00:09<00:04, 13.1MB/s]\r 64%|██████▎   | 107M/169M [00:09<00:04, 13.3MB/s]\r 65%|██████▌   | 111M/169M [00:09<00:04, 13.6MB/s]\r 67%|██████▋   | 114M/169M [00:09<00:04, 13.7MB/s]\r 69%|██████▉   | 117M/169M [00:09<00:03, 13.8MB/s]\r 71%|███████   | 120M/169M [00:10<00:03, 13.8MB/s]\r 73%|███████▎  | 123M/169M [00:10<00:03, 13.8MB/s]\r 75%|███████▍  | 126M/169M [00:10<00:03, 13.9MB/s]\r 76%|███████▋  | 129M/169M [00:10<00:02, 13.9MB/s]\r 78%|███████▊  | 132M/169M [00:11<00:02, 13.8MB/s]\r 80%|████████  | 135M/169M [00:11<00:02, 13.9MB/s]\r 82%|████████▏ | 138M/169M [00:11<00:02, 14.1MB/s]\r 84%|████████▍ | 142M/169M [00:11<00:01, 14.1MB/s]\r 86%|████████▌ | 145M/169M [00:11<00:01, 14.1MB/s]\r 87%|████████▋ | 148M/169M [00:12<00:01, 14.2MB/s]\r 89%|████████▉ | 151M/169M [00:12<00:01, 14.3MB/s]\r 91%|█████████▏| 154M/169M [00:12<00:01, 14.4MB/s]\r 93%|█████████▎| 157M/169M [00:12<00:00, 14.4MB/s]\r 95%|█████████▌| 161M/169M [00:13<00:00, 14.5MB/s]\r 97%|█████████▋| 164M/169M [00:13<00:00, 14.5MB/s]\r 99%|█████████▊| 167M/169M [00:13<00:00, 14.3MB/s]\r100%|██████████| 169M/169M [00:13<00:00, 12.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uu4aWwwOHI3",
        "outputId": "53d8c0bb-7077-44ed-8a82-12653af8b702"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipdb\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.12/dist-packages (from ipdb) (7.34.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.31.1->ipdb)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb) (0.2.14)\n",
            "Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, ipdb\n",
            "Successfully installed ipdb-0.13.13 jedi-0.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvCq-1T10dgZ",
        "outputId": "71c0e540-834c-438c-8316-4131afb182c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                                  Version\n",
            "---------------------------------------- -------------------\n",
            "absl-py                                  1.4.0\n",
            "accelerate                               1.12.0\n",
            "access                                   1.1.9\n",
            "affine                                   2.4.0\n",
            "aiofiles                                 24.1.0\n",
            "aiohappyeyeballs                         2.6.1\n",
            "aiohttp                                  3.13.2\n",
            "aiosignal                                1.4.0\n",
            "aiosqlite                                0.21.0\n",
            "alabaster                                1.0.0\n",
            "albucore                                 0.0.24\n",
            "albumentations                           2.0.8\n",
            "ale-py                                   0.11.2\n",
            "alembic                                  1.17.2\n",
            "altair                                   5.5.0\n",
            "annotated-types                          0.7.0\n",
            "antlr4-python3-runtime                   4.9.3\n",
            "anyio                                    4.12.0\n",
            "anywidget                                0.9.21\n",
            "argon2-cffi                              25.1.0\n",
            "argon2-cffi-bindings                     25.1.0\n",
            "array_record                             0.8.3\n",
            "arrow                                    1.4.0\n",
            "arviz                                    0.22.0\n",
            "astropy                                  7.2.0\n",
            "astropy-iers-data                        0.2025.12.8.0.38.44\n",
            "astunparse                               1.6.3\n",
            "atpublic                                 5.1\n",
            "attrs                                    25.4.0\n",
            "audioread                                3.1.0\n",
            "Authlib                                  1.6.5\n",
            "autograd                                 1.8.0\n",
            "babel                                    2.17.0\n",
            "backcall                                 0.2.0\n",
            "beartype                                 0.22.8\n",
            "beautifulsoup4                           4.13.5\n",
            "betterproto                              2.0.0b6\n",
            "bigframes                                2.30.0\n",
            "bigquery-magics                          0.10.3\n",
            "bleach                                   6.3.0\n",
            "blinker                                  1.9.0\n",
            "blis                                     1.3.3\n",
            "blobfile                                 3.1.0\n",
            "blosc2                                   3.12.2\n",
            "bokeh                                    3.7.3\n",
            "Bottleneck                               1.4.2\n",
            "bqplot                                   0.12.45\n",
            "branca                                   0.8.2\n",
            "brotli                                   1.2.0\n",
            "CacheControl                             0.14.4\n",
            "cachetools                               6.2.2\n",
            "catalogue                                2.0.10\n",
            "certifi                                  2025.11.12\n",
            "cffi                                     2.0.0\n",
            "chardet                                  5.2.0\n",
            "charset-normalizer                       3.4.4\n",
            "chex                                     0.1.90\n",
            "clarabel                                 0.11.1\n",
            "click                                    8.3.1\n",
            "click-plugins                            1.1.1.2\n",
            "cligj                                    0.7.2\n",
            "cloudpathlib                             0.23.0\n",
            "cloudpickle                              3.1.2\n",
            "cmake                                    3.31.10\n",
            "cmdstanpy                                1.3.0\n",
            "colorcet                                 3.1.0\n",
            "colorlover                               0.3.0\n",
            "colour                                   0.1.5\n",
            "community                                1.0.0b1\n",
            "confection                               0.1.5\n",
            "cons                                     0.4.7\n",
            "contourpy                                1.3.3\n",
            "cramjam                                  2.11.0\n",
            "cryptography                             43.0.3\n",
            "cuda-bindings                            12.9.4\n",
            "cuda-core                                0.3.2\n",
            "cuda-pathfinder                          1.3.3\n",
            "cuda-python                              12.9.4\n",
            "cuda-toolkit                             12.9.1\n",
            "cudf-cu12                                25.10.0\n",
            "cudf-polars-cu12                         25.10.0\n",
            "cufflinks                                0.17.3\n",
            "cuml-cu12                                25.10.0\n",
            "cupy-cuda12x                             13.6.0\n",
            "curl_cffi                                0.13.0\n",
            "cvxopt                                   1.3.2\n",
            "cvxpy                                    1.6.7\n",
            "cycler                                   0.12.1\n",
            "cyipopt                                  1.5.0\n",
            "cymem                                    2.0.13\n",
            "Cython                                   3.0.12\n",
            "dask                                     2025.9.1\n",
            "dask-cuda                                25.10.0\n",
            "dask-cudf-cu12                           25.10.0\n",
            "dataproc-spark-connect                   1.0.1\n",
            "datasets                                 4.0.0\n",
            "db-dtypes                                1.4.4\n",
            "dbus-python                              1.2.18\n",
            "debugpy                                  1.8.15\n",
            "decorator                                4.4.2\n",
            "defusedxml                               0.7.1\n",
            "deprecation                              2.1.0\n",
            "diffusers                                0.36.0\n",
            "dill                                     0.3.8\n",
            "distributed                              2025.9.1\n",
            "distributed-ucxx-cu12                    0.46.0\n",
            "distro                                   1.9.0\n",
            "dlib                                     19.24.6\n",
            "dm-tree                                  0.1.9\n",
            "docstring_parser                         0.17.0\n",
            "docutils                                 0.21.2\n",
            "dopamine_rl                              4.1.2\n",
            "duckdb                                   1.3.2\n",
            "earthengine-api                          1.5.24\n",
            "easydict                                 1.13\n",
            "editdistance                             0.8.1\n",
            "eerepr                                   0.1.2\n",
            "einops                                   0.8.1\n",
            "en_core_web_sm                           3.8.0\n",
            "entrypoints                              0.4\n",
            "esda                                     2.8.0\n",
            "et_xmlfile                               2.0.0\n",
            "etils                                    1.13.0\n",
            "etuples                                  0.3.10\n",
            "Farama-Notifications                     0.0.4\n",
            "fastai                                   2.8.5\n",
            "fastapi                                  0.118.3\n",
            "fastcore                                 1.8.17\n",
            "fastdownload                             0.0.7\n",
            "fastjsonschema                           2.21.2\n",
            "fastprogress                             1.0.3\n",
            "fastrlock                                0.8.3\n",
            "fasttransform                            0.0.2\n",
            "ffmpy                                    1.0.0\n",
            "filelock                                 3.20.0\n",
            "fiona                                    1.10.1\n",
            "firebase-admin                           6.9.0\n",
            "Flask                                    3.1.2\n",
            "flatbuffers                              25.9.23\n",
            "flax                                     0.10.7\n",
            "folium                                   0.20.0\n",
            "fonttools                                4.61.0\n",
            "fqdn                                     1.5.1\n",
            "frozendict                               2.4.7\n",
            "frozenlist                               1.8.0\n",
            "fsspec                                   2025.3.0\n",
            "ftfy                                     6.3.1\n",
            "future                                   1.0.0\n",
            "gast                                     0.7.0\n",
            "gcsfs                                    2025.3.0\n",
            "GDAL                                     3.8.4\n",
            "gdown                                    5.2.0\n",
            "geemap                                   0.35.3\n",
            "geocoder                                 1.38.1\n",
            "geographiclib                            2.1\n",
            "geopandas                                1.1.1\n",
            "geopy                                    2.4.1\n",
            "giddy                                    2.3.8\n",
            "gin-config                               0.5.0\n",
            "gitdb                                    4.0.12\n",
            "GitPython                                3.1.45\n",
            "glob2                                    0.7\n",
            "google                                   3.0.0\n",
            "google-adk                               1.20.0\n",
            "google-ai-generativelanguage             0.6.15\n",
            "google-api-core                          2.28.1\n",
            "google-api-python-client                 2.187.0\n",
            "google-auth                              2.43.0\n",
            "google-auth-httplib2                     0.2.1\n",
            "google-auth-oauthlib                     1.2.2\n",
            "google-cloud-aiplatform                  1.129.0\n",
            "google-cloud-appengine-logging           1.7.0\n",
            "google-cloud-audit-log                   0.4.0\n",
            "google-cloud-bigquery                    3.38.0\n",
            "google-cloud-bigquery-connection         1.19.0\n",
            "google-cloud-bigquery-storage            2.35.0\n",
            "google-cloud-bigtable                    2.34.0\n",
            "google-cloud-core                        2.5.0\n",
            "google-cloud-dataproc                    5.23.0\n",
            "google-cloud-datastore                   2.21.0\n",
            "google-cloud-discoveryengine             0.13.12\n",
            "google-cloud-firestore                   2.21.0\n",
            "google-cloud-functions                   1.21.0\n",
            "google-cloud-language                    2.18.0\n",
            "google-cloud-logging                     3.12.1\n",
            "google-cloud-monitoring                  2.28.0\n",
            "google-cloud-resource-manager            1.15.0\n",
            "google-cloud-secret-manager              2.25.0\n",
            "google-cloud-spanner                     3.59.0\n",
            "google-cloud-speech                      2.34.0\n",
            "google-cloud-storage                     3.7.0\n",
            "google-cloud-trace                       1.17.0\n",
            "google-cloud-translate                   3.23.0\n",
            "google-colab                             1.0.0\n",
            "google-crc32c                            1.7.1\n",
            "google-genai                             1.54.0\n",
            "google-generativeai                      0.8.5\n",
            "google-pasta                             0.2.0\n",
            "google-resumable-media                   2.8.0\n",
            "googleapis-common-protos                 1.72.0\n",
            "googledrivedownloader                    1.1.0\n",
            "gradio                                   5.50.0\n",
            "gradio_client                            1.14.0\n",
            "graphviz                                 0.21\n",
            "greenlet                                 3.3.0\n",
            "groovy                                   0.1.2\n",
            "grpc-google-iam-v1                       0.14.3\n",
            "grpc-interceptor                         0.15.4\n",
            "grpcio                                   1.76.0\n",
            "grpcio-status                            1.71.2\n",
            "grpclib                                  0.4.8\n",
            "gspread                                  6.2.1\n",
            "gspread-dataframe                        4.0.0\n",
            "gym                                      0.25.2\n",
            "gym-notices                              0.1.0\n",
            "gymnasium                                1.2.2\n",
            "h11                                      0.16.0\n",
            "h2                                       4.3.0\n",
            "h5netcdf                                 1.7.3\n",
            "h5py                                     3.15.1\n",
            "hdbscan                                  0.8.40\n",
            "hf_transfer                              0.1.9\n",
            "hf-xet                                   1.2.0\n",
            "highspy                                  1.12.0\n",
            "holidays                                 0.86\n",
            "holoviews                                1.22.1\n",
            "hpack                                    4.1.0\n",
            "html5lib                                 1.1\n",
            "httpcore                                 1.0.9\n",
            "httpimport                               1.4.1\n",
            "httplib2                                 0.31.0\n",
            "httpx                                    0.28.1\n",
            "httpx-sse                                0.4.3\n",
            "huggingface-hub                          0.36.0\n",
            "humanize                                 4.14.0\n",
            "hyperframe                               6.1.0\n",
            "hyperopt                                 0.2.7\n",
            "ibis-framework                           9.5.0\n",
            "idna                                     3.11\n",
            "ImageIO                                  2.37.2\n",
            "imageio-ffmpeg                           0.6.0\n",
            "imagesize                                1.4.1\n",
            "imbalanced-learn                         0.14.0\n",
            "immutabledict                            4.2.2\n",
            "importlib_metadata                       8.7.0\n",
            "importlib_resources                      6.5.2\n",
            "imutils                                  0.5.4\n",
            "inequality                               1.1.2\n",
            "inflect                                  7.5.0\n",
            "iniconfig                                2.3.0\n",
            "intel-cmplr-lib-ur                       2025.3.1\n",
            "intel-openmp                             2025.3.1\n",
            "ipdb                                     0.13.13\n",
            "ipyevents                                2.0.4\n",
            "ipyfilechooser                           0.6.0\n",
            "ipykernel                                6.17.1\n",
            "ipyleaflet                               0.20.0\n",
            "ipyparallel                              8.8.0\n",
            "ipython                                  7.34.0\n",
            "ipython-genutils                         0.2.0\n",
            "ipython-sql                              0.5.0\n",
            "ipytree                                  0.2.2\n",
            "ipywidgets                               7.7.1\n",
            "isoduration                              20.11.0\n",
            "itsdangerous                             2.2.0\n",
            "jaraco.classes                           3.4.0\n",
            "jaraco.context                           6.0.1\n",
            "jaraco.functools                         4.3.0\n",
            "jax                                      0.7.2\n",
            "jax-cuda12-pjrt                          0.7.2\n",
            "jax-cuda12-plugin                        0.7.2\n",
            "jaxlib                                   0.7.2\n",
            "jedi                                     0.19.2\n",
            "jeepney                                  0.9.0\n",
            "jieba                                    0.42.1\n",
            "Jinja2                                   3.1.6\n",
            "jiter                                    0.12.0\n",
            "joblib                                   1.5.2\n",
            "jsonpatch                                1.33\n",
            "jsonpickle                               4.1.1\n",
            "jsonpointer                              3.0.0\n",
            "jsonschema                               4.25.1\n",
            "jsonschema-specifications                2025.9.1\n",
            "jupyter_client                           7.4.9\n",
            "jupyter-console                          6.6.3\n",
            "jupyter_core                             5.9.1\n",
            "jupyter-events                           0.12.0\n",
            "jupyter_kernel_gateway                   2.5.2\n",
            "jupyter-leaflet                          0.20.0\n",
            "jupyter_server                           2.14.0\n",
            "jupyter_server_terminals                 0.5.3\n",
            "jupyterlab_pygments                      0.3.0\n",
            "jupyterlab_widgets                       3.0.16\n",
            "jupytext                                 1.18.1\n",
            "kaggle                                   1.7.4.5\n",
            "kagglehub                                0.3.13\n",
            "keras                                    3.10.0\n",
            "keras-hub                                0.21.1\n",
            "keras-nlp                                0.21.1\n",
            "keyring                                  25.7.0\n",
            "keyrings.google-artifactregistry-auth    1.1.2\n",
            "kiwisolver                               1.4.9\n",
            "langchain                                1.1.3\n",
            "langchain-core                           1.1.3\n",
            "langgraph                                1.0.4\n",
            "langgraph-checkpoint                     3.0.1\n",
            "langgraph-prebuilt                       1.0.5\n",
            "langgraph-sdk                            0.2.15\n",
            "langsmith                                0.4.58\n",
            "lark                                     1.3.1\n",
            "launchpadlib                             1.10.16\n",
            "lazr.restfulclient                       0.14.4\n",
            "lazr.uri                                 1.0.6\n",
            "lazy_loader                              0.4\n",
            "libclang                                 18.1.1\n",
            "libcudf-cu12                             25.10.0\n",
            "libcugraph-cu12                          25.10.1\n",
            "libcuml-cu12                             25.10.0\n",
            "libkvikio-cu12                           25.10.0\n",
            "libpysal                                 4.13.0\n",
            "libraft-cu12                             25.10.0\n",
            "librmm-cu12                              25.10.0\n",
            "librosa                                  0.11.0\n",
            "libucx-cu12                              1.19.0\n",
            "libucxx-cu12                             0.46.0\n",
            "lightgbm                                 4.6.0\n",
            "linkify-it-py                            2.0.3\n",
            "llvmlite                                 0.43.0\n",
            "lmdb                                     1.7.5\n",
            "locket                                   1.0.0\n",
            "logical-unification                      0.4.7\n",
            "lxml                                     6.0.2\n",
            "Mako                                     1.3.10\n",
            "mapclassify                              2.10.0\n",
            "Markdown                                 3.10\n",
            "markdown-it-py                           4.0.0\n",
            "MarkupSafe                               3.0.3\n",
            "matplotlib                               3.10.0\n",
            "matplotlib-inline                        0.2.1\n",
            "matplotlib-venn                          1.1.2\n",
            "mcp                                      1.23.3\n",
            "mdit-py-plugins                          0.5.0\n",
            "mdurl                                    0.1.2\n",
            "mgwr                                     2.2.1\n",
            "miniKanren                               1.0.5\n",
            "missingno                                0.5.2\n",
            "mistune                                  3.1.4\n",
            "mizani                                   0.13.5\n",
            "mkl                                      2025.3.0\n",
            "ml_dtypes                                0.5.4\n",
            "mlxtend                                  0.23.4\n",
            "momepy                                   0.10.0\n",
            "more-itertools                           10.8.0\n",
            "moviepy                                  1.0.3\n",
            "mpmath                                   1.3.0\n",
            "msgpack                                  1.1.2\n",
            "multidict                                6.7.0\n",
            "multipledispatch                         1.0.0\n",
            "multiprocess                             0.70.16\n",
            "multitasking                             0.0.12\n",
            "murmurhash                               1.0.15\n",
            "music21                                  9.9.1\n",
            "namex                                    0.1.0\n",
            "narwhals                                 2.13.0\n",
            "natsort                                  8.4.0\n",
            "nbclassic                                1.3.3\n",
            "nbclient                                 0.10.2\n",
            "nbconvert                                7.16.6\n",
            "nbformat                                 5.10.4\n",
            "ndindex                                  1.10.1\n",
            "nest-asyncio                             1.6.0\n",
            "networkx                                 3.6.1\n",
            "nibabel                                  5.3.3\n",
            "nltk                                     3.9.1\n",
            "notebook                                 6.5.7\n",
            "notebook_shim                            0.2.4\n",
            "numba                                    0.60.0\n",
            "numba-cuda                               0.19.1\n",
            "numexpr                                  2.14.1\n",
            "numpy                                    2.0.2\n",
            "nvidia-cublas-cu12                       12.6.4.1\n",
            "nvidia-cuda-cccl-cu12                    12.9.27\n",
            "nvidia-cuda-cupti-cu12                   12.6.80\n",
            "nvidia-cuda-nvcc-cu12                    12.5.82\n",
            "nvidia-cuda-nvrtc-cu12                   12.6.77\n",
            "nvidia-cuda-runtime-cu12                 12.6.77\n",
            "nvidia-cudnn-cu12                        9.10.2.21\n",
            "nvidia-cufft-cu12                        11.3.0.4\n",
            "nvidia-cufile-cu12                       1.11.1.6\n",
            "nvidia-curand-cu12                       10.3.7.77\n",
            "nvidia-cusolver-cu12                     11.7.1.2\n",
            "nvidia-cusparse-cu12                     12.5.4.2\n",
            "nvidia-cusparselt-cu12                   0.7.1\n",
            "nvidia-ml-py                             13.590.44\n",
            "nvidia-nccl-cu12                         2.27.5\n",
            "nvidia-nvjitlink-cu12                    12.6.85\n",
            "nvidia-nvshmem-cu12                      3.3.20\n",
            "nvidia-nvtx-cu12                         12.6.77\n",
            "nvtx                                     0.2.14\n",
            "nx-cugraph-cu12                          25.10.0\n",
            "oauth2client                             4.1.3\n",
            "oauthlib                                 3.3.1\n",
            "omegaconf                                2.3.0\n",
            "onemkl-license                           2025.3.0\n",
            "openai                                   2.9.0\n",
            "opencv-contrib-python                    4.12.0.88\n",
            "opencv-python                            4.12.0.88\n",
            "opencv-python-headless                   4.12.0.88\n",
            "openpyxl                                 3.1.5\n",
            "opentelemetry-api                        1.37.0\n",
            "opentelemetry-exporter-gcp-logging       1.11.0a0\n",
            "opentelemetry-exporter-gcp-monitoring    1.11.0a0\n",
            "opentelemetry-exporter-gcp-trace         1.11.0\n",
            "opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "opentelemetry-exporter-otlp-proto-http   1.37.0\n",
            "opentelemetry-proto                      1.37.0\n",
            "opentelemetry-resourcedetector-gcp       1.11.0a0\n",
            "opentelemetry-sdk                        1.37.0\n",
            "opentelemetry-semantic-conventions       0.58b0\n",
            "opt_einsum                               3.4.0\n",
            "optax                                    0.2.6\n",
            "optree                                   0.18.0\n",
            "orbax-checkpoint                         0.11.30\n",
            "orjson                                   3.11.5\n",
            "ormsgpack                                1.12.0\n",
            "osqp                                     1.0.5\n",
            "overrides                                7.7.0\n",
            "packaging                                25.0\n",
            "pandas                                   2.2.2\n",
            "pandas-datareader                        0.10.0\n",
            "pandas-gbq                               0.30.0\n",
            "pandas-stubs                             2.2.2.240909\n",
            "pandocfilters                            1.5.1\n",
            "panel                                    1.8.4\n",
            "param                                    2.3.1\n",
            "parso                                    0.8.5\n",
            "parsy                                    2.2\n",
            "partd                                    1.4.2\n",
            "patsy                                    1.0.2\n",
            "peewee                                   3.18.3\n",
            "peft                                     0.18.0\n",
            "pexpect                                  4.9.0\n",
            "pickleshare                              0.7.5\n",
            "pillow                                   11.3.0\n",
            "pip                                      24.1.2\n",
            "platformdirs                             4.5.1\n",
            "plotly                                   5.24.1\n",
            "plotnine                                 0.14.5\n",
            "pluggy                                   1.6.0\n",
            "plum-dispatch                            2.6.0\n",
            "ply                                      3.11\n",
            "pointpats                                2.5.2\n",
            "polars                                   1.31.0\n",
            "pooch                                    1.8.2\n",
            "portpicker                               1.5.2\n",
            "preshed                                  3.0.12\n",
            "prettytable                              3.17.0\n",
            "proglog                                  0.1.12\n",
            "progressbar2                             4.5.0\n",
            "prometheus_client                        0.23.1\n",
            "promise                                  2.3\n",
            "prompt_toolkit                           3.0.52\n",
            "propcache                                0.4.1\n",
            "prophet                                  1.2.1\n",
            "proto-plus                               1.26.1\n",
            "protobuf                                 5.29.5\n",
            "psutil                                   5.9.5\n",
            "psycopg2                                 2.9.11\n",
            "psygnal                                  0.15.0\n",
            "ptyprocess                               0.7.0\n",
            "PuLP                                     3.3.0\n",
            "py-cpuinfo                               9.0.0\n",
            "py4j                                     0.10.9.9\n",
            "pyarrow                                  18.1.0\n",
            "pyasn1                                   0.6.1\n",
            "pyasn1_modules                           0.4.2\n",
            "pycairo                                  1.29.0\n",
            "pycocotools                              2.0.10\n",
            "pycparser                                2.23\n",
            "pycryptodomex                            3.23.0\n",
            "pydantic                                 2.12.3\n",
            "pydantic_core                            2.41.4\n",
            "pydantic-settings                        2.12.0\n",
            "pydata-google-auth                       1.9.1\n",
            "pydot                                    4.0.1\n",
            "pydotplus                                2.0.2\n",
            "PyDrive2                                 1.21.3\n",
            "pydub                                    0.25.1\n",
            "pyerfa                                   2.0.1.5\n",
            "pygame                                   2.6.1\n",
            "pygit2                                   1.19.0\n",
            "Pygments                                 2.19.2\n",
            "PyGObject                                3.48.2\n",
            "PyJWT                                    2.10.1\n",
            "pylibcudf-cu12                           25.10.0\n",
            "pylibcugraph-cu12                        25.10.1\n",
            "pylibraft-cu12                           25.10.0\n",
            "pymc                                     5.26.1\n",
            "pynndescent                              0.5.13\n",
            "pyogrio                                  0.12.1\n",
            "pyomo                                    6.9.5\n",
            "PyOpenGL                                 3.1.10\n",
            "pyOpenSSL                                24.2.1\n",
            "pyparsing                                3.2.5\n",
            "pyperclip                                1.11.0\n",
            "pyproj                                   3.7.2\n",
            "pysal                                    25.7\n",
            "pyshp                                    3.0.3\n",
            "PySocks                                  1.7.1\n",
            "pyspark                                  4.0.1\n",
            "pytensor                                 2.35.1\n",
            "pytest                                   8.4.2\n",
            "python-apt                               0.0.0\n",
            "python-box                               7.3.2\n",
            "python-dateutil                          2.9.0.post0\n",
            "python-dotenv                            1.2.1\n",
            "python-json-logger                       4.0.0\n",
            "python-louvain                           0.16\n",
            "python-multipart                         0.0.20\n",
            "python-slugify                           8.0.4\n",
            "python-snappy                            0.7.3\n",
            "python-utils                             3.9.1\n",
            "pytz                                     2025.2\n",
            "pyviz_comms                              3.0.6\n",
            "PyWavelets                               1.9.0\n",
            "PyYAML                                   6.0.3\n",
            "pyzmq                                    26.2.1\n",
            "quantecon                                0.10.1\n",
            "raft-dask-cu12                           25.10.0\n",
            "rapids-dask-dependency                   25.10.0\n",
            "rapids-logger                            0.1.19\n",
            "rasterio                                 1.4.3\n",
            "rasterstats                              0.20.0\n",
            "ratelim                                  0.1.6\n",
            "referencing                              0.37.0\n",
            "regex                                    2025.11.3\n",
            "requests                                 2.32.4\n",
            "requests-oauthlib                        2.0.0\n",
            "requests-toolbelt                        1.0.0\n",
            "requirements-parser                      0.9.0\n",
            "rfc3339-validator                        0.1.4\n",
            "rfc3986-validator                        0.1.1\n",
            "rfc3987-syntax                           1.1.0\n",
            "rich                                     13.9.4\n",
            "rmm-cu12                                 25.10.0\n",
            "roman-numerals-py                        3.1.0\n",
            "rpds-py                                  0.30.0\n",
            "rpy2                                     3.5.17\n",
            "rsa                                      4.9.1\n",
            "rtree                                    1.4.1\n",
            "ruff                                     0.14.8\n",
            "safehttpx                                0.1.7\n",
            "safetensors                              0.7.0\n",
            "scikit-image                             0.25.2\n",
            "scikit-learn                             1.6.1\n",
            "scipy                                    1.16.3\n",
            "scooby                                   0.11.0\n",
            "scs                                      3.2.9\n",
            "seaborn                                  0.13.2\n",
            "SecretStorage                            3.5.0\n",
            "segregation                              2.5.3\n",
            "semantic-version                         2.10.0\n",
            "Send2Trash                               1.8.3\n",
            "sentence-transformers                    5.1.2\n",
            "sentencepiece                            0.2.1\n",
            "sentry-sdk                               2.47.0\n",
            "setuptools                               75.2.0\n",
            "shap                                     0.50.0\n",
            "shapely                                  2.1.2\n",
            "shellingham                              1.5.4\n",
            "simple-parsing                           0.1.7\n",
            "simplejson                               3.20.2\n",
            "simsimd                                  6.5.3\n",
            "six                                      1.17.0\n",
            "sklearn-pandas                           2.2.0\n",
            "slicer                                   0.0.8\n",
            "smart_open                               7.5.0\n",
            "smmap                                    5.0.2\n",
            "sniffio                                  1.3.1\n",
            "snowballstemmer                          3.0.1\n",
            "sortedcontainers                         2.4.0\n",
            "soundfile                                0.13.1\n",
            "soupsieve                                2.8\n",
            "soxr                                     1.0.0\n",
            "spacy                                    3.8.11\n",
            "spacy-legacy                             3.0.12\n",
            "spacy-loggers                            1.0.5\n",
            "spaghetti                                1.7.6\n",
            "spanner-graph-notebook                   1.1.8\n",
            "spglm                                    1.1.0\n",
            "Sphinx                                   8.2.3\n",
            "sphinxcontrib-applehelp                  2.0.0\n",
            "sphinxcontrib-devhelp                    2.0.0\n",
            "sphinxcontrib-htmlhelp                   2.1.0\n",
            "sphinxcontrib-jsmath                     1.0.1\n",
            "sphinxcontrib-qthelp                     2.0.0\n",
            "sphinxcontrib-serializinghtml            2.0.0\n",
            "spint                                    1.0.7\n",
            "splot                                    1.1.7\n",
            "spopt                                    0.7.0\n",
            "spreg                                    1.8.4\n",
            "SQLAlchemy                               2.0.45\n",
            "sqlalchemy-spanner                       1.17.1\n",
            "sqlglot                                  25.20.2\n",
            "sqlparse                                 0.5.4\n",
            "srsly                                    2.5.2\n",
            "sse-starlette                            3.0.3\n",
            "stanio                                   0.5.1\n",
            "starlette                                0.48.0\n",
            "statsmodels                              0.14.6\n",
            "stringzilla                              4.4.0\n",
            "stumpy                                   1.13.0\n",
            "sympy                                    1.14.0\n",
            "tables                                   3.10.2\n",
            "tabulate                                 0.9.0\n",
            "tbb                                      2022.3.0\n",
            "tblib                                    3.2.2\n",
            "tcmlib                                   1.4.1\n",
            "tenacity                                 9.1.2\n",
            "tensorboard                              2.19.0\n",
            "tensorboard-data-server                  0.7.2\n",
            "tensorflow                               2.19.0\n",
            "tensorflow-datasets                      4.9.9\n",
            "tensorflow_decision_forests              1.12.0\n",
            "tensorflow-hub                           0.16.1\n",
            "tensorflow-metadata                      1.17.2\n",
            "tensorflow-probability                   0.25.0\n",
            "tensorflow-text                          2.19.0\n",
            "tensorstore                              0.1.79\n",
            "termcolor                                3.2.0\n",
            "terminado                                0.18.1\n",
            "text-unidecode                           1.3\n",
            "textblob                                 0.19.0\n",
            "tf_keras                                 2.19.0\n",
            "tf-slim                                  1.1.0\n",
            "thinc                                    8.3.10\n",
            "threadpoolctl                            3.6.0\n",
            "tifffile                                 2025.10.16\n",
            "tiktoken                                 0.12.0\n",
            "timm                                     0.6.7\n",
            "tinycss2                                 1.4.0\n",
            "tobler                                   0.12.1\n",
            "tokenizers                               0.22.1\n",
            "toml                                     0.10.2\n",
            "tomlkit                                  0.13.3\n",
            "toolz                                    0.12.1\n",
            "torch                                    2.9.0+cu126\n",
            "torchao                                  0.10.0\n",
            "torchaudio                               2.9.0+cu126\n",
            "torchdata                                0.11.0\n",
            "torchsummary                             1.5.1\n",
            "torchtune                                0.6.1\n",
            "torchvision                              0.24.0+cu126\n",
            "tornado                                  6.5.1\n",
            "tqdm                                     4.67.1\n",
            "traitlets                                5.7.1\n",
            "traittypes                               0.2.3\n",
            "transformers                             4.57.3\n",
            "treelite                                 4.4.1\n",
            "treescope                                0.1.10\n",
            "triton                                   3.5.0\n",
            "tsfresh                                  0.21.1\n",
            "tweepy                                   4.16.0\n",
            "typeguard                                4.4.4\n",
            "typer                                    0.20.0\n",
            "typer-slim                               0.20.0\n",
            "types-pytz                               2025.2.0.20251108\n",
            "types-setuptools                         80.9.0.20250822\n",
            "typing_extensions                        4.15.0\n",
            "typing-inspection                        0.4.2\n",
            "tzdata                                   2025.2\n",
            "tzlocal                                  5.3.1\n",
            "uc-micro-py                              1.0.3\n",
            "ucxx-cu12                                0.46.0\n",
            "umap-learn                               0.5.9.post2\n",
            "umf                                      1.0.2\n",
            "uri-template                             1.3.0\n",
            "uritemplate                              4.2.0\n",
            "urllib3                                  2.5.0\n",
            "uuid_utils                               0.12.0\n",
            "uvicorn                                  0.38.0\n",
            "vega-datasets                            0.9.0\n",
            "wadllib                                  1.3.6\n",
            "wandb                                    0.23.1\n",
            "wasabi                                   1.1.3\n",
            "watchdog                                 6.0.0\n",
            "wcwidth                                  0.2.14\n",
            "weasel                                   0.4.3\n",
            "webcolors                                25.10.0\n",
            "webencodings                             0.5.1\n",
            "websocket-client                         1.9.0\n",
            "websockets                               15.0.1\n",
            "Werkzeug                                 3.1.4\n",
            "wheel                                    0.45.1\n",
            "widgetsnbextension                       3.6.10\n",
            "wordcloud                                1.9.4\n",
            "wrapt                                    2.0.1\n",
            "wurlitzer                                3.1.1\n",
            "xarray                                   2025.12.0\n",
            "xarray-einstats                          0.9.1\n",
            "xgboost                                  3.1.2\n",
            "xlrd                                     2.0.2\n",
            "xxhash                                   3.6.0\n",
            "xyzservices                              2025.11.0\n",
            "yarl                                     1.22.0\n",
            "ydf                                      0.13.0\n",
            "yellowbrick                              1.5\n",
            "yfinance                                 0.2.66\n",
            "zict                                     3.0.0\n",
            "zipp                                     3.23.0\n",
            "zstandard                                0.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt\n"
      ],
      "metadata": {
        "id": "o4n_D0zO1Y2d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 把这个 cell 整体复制到 Colab 的 Python cell 里运行\n",
        "import json, os\n",
        "debug_cfg = {\n",
        "    \"prefix\": \"reproduce_debug\",\n",
        "    \"dataset\": \"cifar100\",\n",
        "    \"data_path\": \"data/\",\n",
        "    \"memory_size\": 0,\n",
        "    \"memory_per_class\": 0,\n",
        "    \"fixed_memory\": True,\n",
        "    \"shuffle\": False,\n",
        "    \"init_cls\": 10,\n",
        "    \"increment\": 10,\n",
        "    # 只跑两个 session（init + 1 increment）用于快速验证\n",
        "    \"total_sessions\" : 2,\n",
        "    \"model_name\": \"InfLoRA\",\n",
        "    \"net_type\": \"sip\",\n",
        "    \"embd_dim\" : 768,\n",
        "    \"num_heads\": 12,\n",
        "    \"seed\": [0],\n",
        "    \"EPSILON\" : 1e-8,\n",
        "    # 减小轮数以便快速通过 pipeline\n",
        "    \"init_epoch\" : 2,\n",
        "    \"optim\" : \"adam\",\n",
        "    \"init_lr\" : 0.0005,\n",
        "    \"init_lr_decay\" : 0.1,\n",
        "    \"init_weight_decay\" : 0.0,\n",
        "    \"epochs\" : 2,\n",
        "    \"lrate\" : 0.0005,\n",
        "    \"lrate_decay\" : 0.1,\n",
        "    # 更小的 batch 以适应 Colab 显存\n",
        "    \"batch_size\" : 32,\n",
        "    \"weight_decay\" : 0.0,\n",
        "    # 更小的 adapter rank，减少计算\n",
        "    \"rank\": 4,\n",
        "    \"lamb\": 0.95,\n",
        "    \"lame\": 1.0,\n",
        "    # 减少 workers\n",
        "    \"num_workers\" : 2\n",
        "}\n",
        "\n",
        "os.makedirs(\"configs\", exist_ok=True)\n",
        "debug_path = \"configs/cifar100_inflora_debug.json\"\n",
        "with open(debug_path, \"w\") as f:\n",
        "    json.dump(debug_cfg, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"Wrote debug config to\", debug_path)\n",
        "print(open(debug_path).read())\n",
        "\n",
        "# 运行命令（下面是两种 device 写法，按 main.py 支持的格式选其一）\n",
        "print(\"\\n--- 运行命令示例 ---\")\n",
        "print(\"方式 A (device 0):\")\n",
        "print(\"!python main.py --device 0 --config configs/cifar100_inflora_debug.json\")\n",
        "print(\"\\n方式 B (device cuda:0):\")\n",
        "print(\"!python main.py --device cuda:0 --config configs/cifar100_inflora_debug.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7fnSrAycEzb",
        "outputId": "19441a62-89dc-42a3-9da0-0e8a88bae423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote debug config to configs/cifar100_inflora_debug.json\n",
            "{\n",
            "  \"prefix\": \"reproduce_debug\",\n",
            "  \"dataset\": \"cifar100\",\n",
            "  \"data_path\": \"data/\",\n",
            "  \"memory_size\": 0,\n",
            "  \"memory_per_class\": 0,\n",
            "  \"fixed_memory\": true,\n",
            "  \"shuffle\": false,\n",
            "  \"init_cls\": 10,\n",
            "  \"increment\": 10,\n",
            "  \"total_sessions\": 2,\n",
            "  \"model_name\": \"InfLoRA\",\n",
            "  \"net_type\": \"sip\",\n",
            "  \"embd_dim\": 768,\n",
            "  \"num_heads\": 12,\n",
            "  \"seed\": [\n",
            "    0\n",
            "  ],\n",
            "  \"EPSILON\": 1e-08,\n",
            "  \"init_epoch\": 2,\n",
            "  \"optim\": \"adam\",\n",
            "  \"init_lr\": 0.0005,\n",
            "  \"init_lr_decay\": 0.1,\n",
            "  \"init_weight_decay\": 0.0,\n",
            "  \"epochs\": 2,\n",
            "  \"lrate\": 0.0005,\n",
            "  \"lrate_decay\": 0.1,\n",
            "  \"batch_size\": 32,\n",
            "  \"weight_decay\": 0.0,\n",
            "  \"rank\": 4,\n",
            "  \"lamb\": 0.95,\n",
            "  \"lame\": 1.0,\n",
            "  \"num_workers\": 2\n",
            "}\n",
            "\n",
            "--- 运行命令示例 ---\n",
            "方式 A (device 0):\n",
            "!python main.py --device 0 --config configs/cifar100_inflora_debug.json\n",
            "\n",
            "方式 B (device cuda:0):\n",
            "!python main.py --device cuda:0 --config configs/cifar100_inflora_debug.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --device 0 --config configs/cifar100_inflora_debug.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Jy7C12Cc1ka",
        "outputId": "4d8a4dbe-318f-4e80-a41e-c19e2eed5517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logs/cifar100/10_10_sip/InfLoRA/adam/4/0.95_1.0-0.0005/0\n",
            "2025-12-14 06:40:55,219 [trainer.py] => config: configs/cifar100_inflora_debug.json\n",
            "2025-12-14 06:40:55,219 [trainer.py] => device: [device(type='cuda', index=0)]\n",
            "2025-12-14 06:40:55,219 [trainer.py] => prefix: reproduce_debug\n",
            "2025-12-14 06:40:55,219 [trainer.py] => dataset: cifar100\n",
            "2025-12-14 06:40:55,219 [trainer.py] => data_path: data/\n",
            "2025-12-14 06:40:55,219 [trainer.py] => memory_size: 0\n",
            "2025-12-14 06:40:55,219 [trainer.py] => memory_per_class: 0\n",
            "2025-12-14 06:40:55,219 [trainer.py] => fixed_memory: True\n",
            "2025-12-14 06:40:55,220 [trainer.py] => shuffle: False\n",
            "2025-12-14 06:40:55,220 [trainer.py] => init_cls: 10\n",
            "2025-12-14 06:40:55,220 [trainer.py] => increment: 10\n",
            "2025-12-14 06:40:55,220 [trainer.py] => total_sessions: 2\n",
            "2025-12-14 06:40:55,220 [trainer.py] => model_name: InfLoRA\n",
            "2025-12-14 06:40:55,220 [trainer.py] => net_type: sip\n",
            "2025-12-14 06:40:55,220 [trainer.py] => embd_dim: 768\n",
            "2025-12-14 06:40:55,220 [trainer.py] => num_heads: 12\n",
            "2025-12-14 06:40:55,220 [trainer.py] => seed: 0\n",
            "2025-12-14 06:40:55,220 [trainer.py] => EPSILON: 1e-08\n",
            "2025-12-14 06:40:55,220 [trainer.py] => init_epoch: 2\n",
            "2025-12-14 06:40:55,220 [trainer.py] => optim: adam\n",
            "2025-12-14 06:40:55,220 [trainer.py] => init_lr: 0.0005\n",
            "2025-12-14 06:40:55,221 [trainer.py] => init_lr_decay: 0.1\n",
            "2025-12-14 06:40:55,221 [trainer.py] => init_weight_decay: 0.0\n",
            "2025-12-14 06:40:55,221 [trainer.py] => epochs: 2\n",
            "2025-12-14 06:40:55,221 [trainer.py] => lrate: 0.0005\n",
            "2025-12-14 06:40:55,221 [trainer.py] => lrate_decay: 0.1\n",
            "2025-12-14 06:40:55,221 [trainer.py] => batch_size: 32\n",
            "2025-12-14 06:40:55,221 [trainer.py] => weight_decay: 0.0\n",
            "2025-12-14 06:40:55,221 [trainer.py] => rank: 4\n",
            "2025-12-14 06:40:55,221 [trainer.py] => lamb: 0.95\n",
            "2025-12-14 06:40:55,221 [trainer.py] => lame: 1.0\n",
            "2025-12-14 06:40:55,221 [trainer.py] => num_workers: 2\n",
            "2025-12-14 06:40:57,023 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "2025-12-14 06:41:00,405 [trainer.py] => All params: 107680123\n",
            "2025-12-14 06:41:00,406 [trainer.py] => Trainable params: 107680123\n",
            "2025-12-14 06:41:00,408 [inflora.py] => Learning on 0-10\n",
            "After enforce: trainable param names count: 26, total trainable elements: 81,418\n",
            "Task 0, Epoch 2/2 => Loss 0.238, Train_accy 92.02: 100% 2/2 [04:46<00:00, 143.37s/it]\n",
            "2025-12-14 06:46:56,639 [inflora.py] => Task 0, Epoch 2/2 => Loss 0.238, Train_accy 92.02\n",
            "Threshold:  0.95\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 6/768 type remove\n",
            "Layer 2 : 9/768 type remove\n",
            "Layer 3 : 11/768 type remove\n",
            "Layer 4 : 11/768 type remove\n",
            "Layer 5 : 13/768 type remove\n",
            "Layer 6 : 15/768 type remove\n",
            "Layer 7 : 14/768 type remove\n",
            "Layer 8 : 19/768 type remove\n",
            "Layer 9 : 25/768 type remove\n",
            "Layer 10 : 21/768 type remove\n",
            "Layer 11 : 6/768 type remove\n",
            "Layer 12 : 19/768 type remove\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 6 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 7 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 8 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 9 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 10 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 11 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 12 - Projection Matrix shape: torch.Size([768, 768])\n",
            "2025-12-14 06:49:16,979 [trainer.py] => Time:496.57302594184875\n",
            "2025-12-14 06:49:30,822 [trainer.py] => Time:13.842060327529907\n",
            "2025-12-14 06:49:30,822 [inflora.py] => Exemplar size: 0\n",
            "2025-12-14 06:49:30,822 [trainer.py] => CNN: {'total': np.float64(98.8), '00-09': np.float64(98.8), 'old': 0, 'new': np.float64(98.8)}\n",
            "2025-12-14 06:49:30,822 [trainer.py] => CNN top1 curve: [np.float64(98.8)]\n",
            "2025-12-14 06:49:30,822 [trainer.py] => CNN top1 with task curve: [np.float64(98.8)]\n",
            "2025-12-14 06:49:30,822 [trainer.py] => CNN top1 task curve: [1.0]\n",
            "2025-12-14 06:49:33,599 [trainer.py] => All params: 107680123\n",
            "2025-12-14 06:49:33,600 [trainer.py] => Trainable params: 81418\n",
            "2025-12-14 06:49:33,601 [inflora.py] => Learning on 10-20\n",
            "After enforce: trainable param names count: 26, total trainable elements: 81,418\n",
            "Task 1, Epoch 2/2 => Loss 0.273, Train_accy 91.10: 100% 2/2 [04:45<00:00, 142.87s/it]\n",
            "2025-12-14 06:55:31,853 [inflora.py] => Task 1, Epoch 2/2 => Loss 0.273, Train_accy 91.10\n",
            "Threshold:  0.975\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 7/768 type remove\n",
            "Layer 2 : 12/768 type remove\n",
            "Layer 3 : 16/768 type remove\n",
            "Layer 4 : 18/768 type remove\n",
            "Layer 5 : 24/768 type remove\n",
            "Layer 6 : 29/768 type remove\n",
            "Layer 7 : 31/768 type remove\n",
            "Layer 8 : 43/768 type remove\n",
            "Layer 9 : 58/768 type remove\n",
            "Layer 10 : 63/768 type remove\n",
            "Layer 11 : 20/768 type remove\n",
            "Layer 12 : 78/768 type remove\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 6 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 7 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 8 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 9 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 10 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 11 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 12 - Projection Matrix shape: torch.Size([768, 768])\n",
            "2025-12-14 06:57:53,050 [trainer.py] => Time:499.44986391067505\n",
            "2025-12-14 06:58:20,362 [trainer.py] => Time:27.310279846191406\n",
            "2025-12-14 06:58:20,363 [inflora.py] => Exemplar size: 0\n",
            "2025-12-14 06:58:20,363 [trainer.py] => CNN: {'total': np.float64(96.0), '00-09': np.float64(97.6), '10-19': np.float64(94.4), 'old': np.float64(97.6), 'new': np.float64(94.4)}\n",
            "2025-12-14 06:58:20,363 [trainer.py] => CNN top1 curve: [np.float64(98.8), np.float64(96.0)]\n",
            "2025-12-14 06:58:20,363 [trainer.py] => CNN top1 with task curve: [np.float64(98.8), np.float64(98.25)]\n",
            "2025-12-14 06:58:20,363 [trainer.py] => CNN top1 task curve: [1.0, 0.972]\n",
            "2025-12-14 06:58:21,351 [trainer.py] => All params: 107680123\n",
            "2025-12-14 06:58:21,352 [trainer.py] => Trainable params: 81418\n",
            "2025-12-14 06:58:21,362 [inflora.py] => Learning on 20-30\n",
            "After enforce: trainable param names count: 26, total trainable elements: 81,418\n",
            "Task 2, Epoch 2/2 => Loss 0.251, Train_accy 91.72: 100% 2/2 [04:46<00:00, 143.49s/it]\n",
            "2025-12-14 07:04:21,160 [inflora.py] => Task 2, Epoch 2/2 => Loss 0.251, Train_accy 91.72\n",
            "Threshold:  1.0\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 0/768 type retain\n",
            "Layer 2 : 0/768 type retain\n",
            "Layer 3 : 0/768 type retain\n",
            "Layer 4 : 0/768 type retain\n",
            "Layer 5 : 0/768 type retain\n",
            "Layer 6 : 0/768 type retain\n",
            "Layer 7 : 0/768 type retain\n",
            "Layer 8 : 0/768 type retain\n",
            "Layer 9 : 0/768 type retain\n",
            "Layer 10 : 0/768 type retain\n",
            "Layer 11 : 0/768 type retain\n",
            "Layer 12 : 0/768 type retain\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 6 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 7 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 8 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 9 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 10 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 11 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 12 - Projection Matrix shape: torch.Size([768, 768])\n",
            "2025-12-14 07:06:45,640 [trainer.py] => Time:504.2881889343262\n",
            "2025-12-14 07:07:26,560 [trainer.py] => Time:40.91877794265747\n",
            "2025-12-14 07:07:26,560 [inflora.py] => Exemplar size: 0\n",
            "2025-12-14 07:07:26,560 [trainer.py] => CNN: {'total': np.float64(93.67), '00-09': np.float64(95.5), '10-19': np.float64(92.3), '20-29': np.float64(93.2), 'old': np.float64(93.9), 'new': np.float64(93.2)}\n",
            "2025-12-14 07:07:26,560 [trainer.py] => CNN top1 curve: [np.float64(98.8), np.float64(96.0), np.float64(93.67)]\n",
            "2025-12-14 07:07:26,560 [trainer.py] => CNN top1 with task curve: [np.float64(98.8), np.float64(98.25), np.float64(98.1)]\n",
            "2025-12-14 07:07:26,560 [trainer.py] => CNN top1 task curve: [1.0, 0.972, 0.9473333333333334]\n",
            "2025-12-14 07:07:27,526 [trainer.py] => All params: 107835269\n",
            "2025-12-14 07:07:27,527 [trainer.py] => Trainable params: 81418\n",
            "2025-12-14 07:07:27,536 [inflora.py] => Learning on 30-40\n",
            "After enforce: trainable param names count: 26, total trainable elements: 81,418\n",
            "Task 3, Epoch 2/2 => Loss 0.241, Train_accy 92.48: 100% 2/2 [04:47<00:00, 143.97s/it]\n",
            "2025-12-14 07:13:27,276 [inflora.py] => Task 3, Epoch 2/2 => Loss 0.241, Train_accy 92.48\n",
            "Threshold:  1.025\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 0/768 type retain\n",
            "Layer 2 : 0/768 type retain\n",
            "Layer 3 : 0/768 type retain\n",
            "Layer 4 : 0/768 type retain\n",
            "Layer 5 : 0/768 type retain\n",
            "Layer 6 : 0/768 type retain\n",
            "Layer 7 : 0/768 type retain\n",
            "Layer 8 : 0/768 type retain\n",
            "Layer 9 : 0/768 type retain\n",
            "Layer 10 : 0/768 type retain\n",
            "Layer 11 : 0/768 type retain\n",
            "Layer 12 : 0/768 type retain\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 6 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 7 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 8 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 9 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 10 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 11 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 12 - Projection Matrix shape: torch.Size([768, 768])\n",
            "2025-12-14 07:15:48,060 [trainer.py] => Time:500.53270864486694\n",
            "2025-12-14 07:16:42,884 [trainer.py] => Time:54.824039697647095\n",
            "2025-12-14 07:16:42,885 [inflora.py] => Exemplar size: 0\n",
            "2025-12-14 07:16:42,885 [trainer.py] => CNN: {'total': np.float64(90.18), '00-09': np.float64(95.1), '10-19': np.float64(89.9), '20-29': np.float64(92.1), '30-39': np.float64(83.6), 'old': np.float64(92.37), 'new': np.float64(83.6)}\n",
            "2025-12-14 07:16:42,885 [trainer.py] => CNN top1 curve: [np.float64(98.8), np.float64(96.0), np.float64(93.67), np.float64(90.18)]\n",
            "2025-12-14 07:16:42,886 [trainer.py] => CNN top1 with task curve: [np.float64(98.8), np.float64(98.25), np.float64(98.1), np.float64(97.9)]\n",
            "2025-12-14 07:16:42,886 [trainer.py] => CNN top1 task curve: [1.0, 0.972, 0.9473333333333334, 0.9115]\n",
            "2025-12-14 07:16:50,393 [trainer.py] => All params: 107990415\n",
            "2025-12-14 07:16:50,395 [trainer.py] => Trainable params: 81418\n",
            "2025-12-14 07:16:50,405 [inflora.py] => Learning on 40-50\n",
            "After enforce: trainable param names count: 26, total trainable elements: 81,418\n",
            "Task 4, Epoch 2/2 => Loss 0.257, Train_accy 91.54: 100% 2/2 [04:47<00:00, 143.67s/it]\n",
            "2025-12-14 07:22:49,891 [inflora.py] => Task 4, Epoch 2/2 => Loss 0.257, Train_accy 91.54\n",
            "Threshold:  1.05\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 0/768 type retain\n",
            "Layer 2 : 0/768 type retain\n",
            "Layer 3 : 0/768 type retain\n",
            "Layer 4 : 0/768 type retain\n",
            "Layer 5 : 0/768 type retain\n",
            "Layer 6 : 0/768 type retain\n",
            "Layer 7 : 0/768 type retain\n",
            "Layer 8 : 0/768 type retain\n",
            "Layer 9 : 0/768 type retain\n",
            "Layer 10 : 0/768 type retain\n",
            "Layer 11 : 0/768 type retain\n",
            "Layer 12 : 0/768 type retain\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 6 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 7 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 8 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 9 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 10 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 11 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 12 - Projection Matrix shape: torch.Size([768, 768])\n",
            "2025-12-14 07:25:10,724 [trainer.py] => Time:500.3288314342499\n",
            "2025-12-14 07:26:19,005 [trainer.py] => Time:68.28099250793457\n",
            "2025-12-14 07:26:19,006 [inflora.py] => Exemplar size: 0\n",
            "2025-12-14 07:26:19,006 [trainer.py] => CNN: {'total': np.float64(88.32), '00-09': np.float64(94.1), '10-19': np.float64(87.5), '20-29': np.float64(91.1), '30-39': np.float64(82.1), '40-49': np.float64(86.8), 'old': np.float64(88.7), 'new': np.float64(86.8)}\n",
            "2025-12-14 07:26:19,006 [trainer.py] => CNN top1 curve: [np.float64(98.8), np.float64(96.0), np.float64(93.67), np.float64(90.18), np.float64(88.32)]\n",
            "2025-12-14 07:26:19,006 [trainer.py] => CNN top1 with task curve: [np.float64(98.8), np.float64(98.25), np.float64(98.1), np.float64(97.9), np.float64(98.04)]\n",
            "2025-12-14 07:26:19,006 [trainer.py] => CNN top1 task curve: [1.0, 0.972, 0.9473333333333334, 0.9115, 0.8908]\n",
            "2025-12-14 07:26:23,763 [trainer.py] => All params: 108145561\n",
            "2025-12-14 07:26:23,764 [trainer.py] => Trainable params: 81418\n",
            "2025-12-14 07:26:23,775 [inflora.py] => Learning on 50-60\n",
            "After enforce: trainable param names count: 26, total trainable elements: 81,418\n",
            "Task 5, Epoch 2/2 => Loss 0.266, Train_accy 91.04: 100% 2/2 [04:47<00:00, 143.67s/it]\n",
            "2025-12-14 07:32:23,333 [inflora.py] => Task 5, Epoch 2/2 => Loss 0.266, Train_accy 91.04\n",
            "Threshold:  1.0750000000000002\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 0/768 type retain\n",
            "Layer 2 : 0/768 type retain\n",
            "Layer 3 : 0/768 type retain\n",
            "Layer 4 : 0/768 type retain\n",
            "Layer 5 : 0/768 type retain\n",
            "Layer 6 : 0/768 type retain\n",
            "Layer 7 : 0/768 type retain\n",
            "Layer 8 : 0/768 type retain\n",
            "Layer 9 : 0/768 type retain\n",
            "Layer 10 : 0/768 type retain\n",
            "Layer 11 : 0/768 type retain\n",
            "Layer 12 : 0/768 type retain\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 6 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 7 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 8 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 9 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 10 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 11 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 12 - Projection Matrix shape: torch.Size([768, 768])\n",
            "2025-12-14 07:34:44,030 [trainer.py] => Time:500.2657103538513\n",
            "2025-12-14 07:36:06,143 [trainer.py] => Time:82.11252546310425\n",
            "2025-12-14 07:36:06,143 [inflora.py] => Exemplar size: 0\n",
            "2025-12-14 07:36:06,144 [trainer.py] => CNN: {'total': np.float64(84.98), '00-09': np.float64(94.7), '10-19': np.float64(85.7), '20-29': np.float64(89.8), '30-39': np.float64(81.5), '40-49': np.float64(85.5), '50-59': np.float64(72.7), 'old': np.float64(87.44), 'new': np.float64(72.7)}\n",
            "2025-12-14 07:36:06,144 [trainer.py] => CNN top1 curve: [np.float64(98.8), np.float64(96.0), np.float64(93.67), np.float64(90.18), np.float64(88.32), np.float64(84.98)]\n",
            "2025-12-14 07:36:06,144 [trainer.py] => CNN top1 with task curve: [np.float64(98.8), np.float64(98.25), np.float64(98.1), np.float64(97.9), np.float64(98.04), np.float64(97.72)]\n",
            "2025-12-14 07:36:06,144 [trainer.py] => CNN top1 task curve: [1.0, 0.972, 0.9473333333333334, 0.9115, 0.8908, 0.8563333333333333]\n",
            "2025-12-14 07:36:07,443 [trainer.py] => All params: 108300707\n",
            "2025-12-14 07:36:07,444 [trainer.py] => Trainable params: 81418\n",
            "2025-12-14 07:36:07,455 [inflora.py] => Learning on 60-70\n",
            "After enforce: trainable param names count: 26, total trainable elements: 81,418\n",
            "Task 6, Epoch 2/2 => Loss 0.288, Train_accy 90.18: 100% 2/2 [04:47<00:00, 143.95s/it]\n",
            "2025-12-14 07:42:07,046 [inflora.py] => Task 6, Epoch 2/2 => Loss 0.288, Train_accy 90.18\n",
            "Threshold:  1.1\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 0/768 type retain\n",
            "Layer 2 : 0/768 type retain\n",
            "Layer 3 : 0/768 type retain\n",
            "Layer 4 : 0/768 type retain\n",
            "Layer 5 : 0/768 type retain\n",
            "Layer 6 : 0/768 type retain\n",
            "Layer 7 : 0/768 type retain\n",
            "Layer 8 : 0/768 type retain\n",
            "Layer 9 : 0/768 type retain\n",
            "Layer 10 : 0/768 type retain\n",
            "Layer 11 : 0/768 type retain\n",
            "Layer 12 : 0/768 type retain\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 6 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 7 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 8 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 9 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 10 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 11 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 12 - Projection Matrix shape: torch.Size([768, 768])\n",
            "2025-12-14 07:44:28,927 [trainer.py] => Time:501.48264145851135\n",
            "2025-12-14 07:46:04,892 [trainer.py] => Time:95.96387600898743\n",
            "2025-12-14 07:46:04,892 [inflora.py] => Exemplar size: 0\n",
            "2025-12-14 07:46:04,893 [trainer.py] => CNN: {'total': np.float64(83.14), '00-09': np.float64(95.3), '10-19': np.float64(84.1), '20-29': np.float64(87.7), '30-39': np.float64(80.0), '40-49': np.float64(85.7), '50-59': np.float64(69.8), '60-69': np.float64(79.4), 'old': np.float64(83.77), 'new': np.float64(79.4)}\n",
            "2025-12-14 07:46:04,893 [trainer.py] => CNN top1 curve: [np.float64(98.8), np.float64(96.0), np.float64(93.67), np.float64(90.18), np.float64(88.32), np.float64(84.98), np.float64(83.14)]\n",
            "2025-12-14 07:46:04,893 [trainer.py] => CNN top1 with task curve: [np.float64(98.8), np.float64(98.25), np.float64(98.1), np.float64(97.9), np.float64(98.04), np.float64(97.72), np.float64(97.6)]\n",
            "2025-12-14 07:46:04,893 [trainer.py] => CNN top1 task curve: [1.0, 0.972, 0.9473333333333334, 0.9115, 0.8908, 0.8563333333333333, 0.8378571428571429]\n",
            "2025-12-14 07:46:06,186 [trainer.py] => All params: 108455853\n",
            "2025-12-14 07:46:06,188 [trainer.py] => Trainable params: 81418\n",
            "2025-12-14 07:46:06,197 [inflora.py] => Learning on 70-80\n",
            "After enforce: trainable param names count: 26, total trainable elements: 81,418\n",
            "Task 7, Epoch 2/2 => Loss 0.252, Train_accy 92.12: 100% 2/2 [04:48<00:00, 144.37s/it]\n",
            "2025-12-14 07:52:07,345 [inflora.py] => Task 7, Epoch 2/2 => Loss 0.252, Train_accy 92.12\n",
            "Threshold:  1.125\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 0/768 type retain\n",
            "Layer 2 : 0/768 type retain\n",
            "Layer 3 : 0/768 type retain\n",
            "Layer 4 : 0/768 type retain\n",
            "Layer 5 : 0/768 type retain\n",
            "Layer 6 : 0/768 type retain\n",
            "Layer 7 : 0/768 type retain\n",
            "Layer 8 : 0/768 type retain\n",
            "Layer 9 : 0/768 type retain\n",
            "Layer 10 : 0/768 type retain\n",
            "Layer 11 : 0/768 type retain\n",
            "Layer 12 : 0/768 type retain\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 6 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 7 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 8 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 9 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 10 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 11 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 12 - Projection Matrix shape: torch.Size([768, 768])\n",
            "2025-12-14 07:54:29,416 [trainer.py] => Time:503.228303194046\n",
            "2025-12-14 07:56:19,513 [trainer.py] => Time:110.09479665756226\n",
            "2025-12-14 07:56:19,513 [inflora.py] => Exemplar size: 0\n",
            "2025-12-14 07:56:19,513 [trainer.py] => CNN: {'total': np.float64(82.28), '00-09': np.float64(93.9), '10-19': np.float64(84.9), '20-29': np.float64(87.0), '30-39': np.float64(79.7), '40-49': np.float64(85.4), '50-59': np.float64(68.3), '60-69': np.float64(77.9), '70-79': np.float64(81.1), 'old': np.float64(82.44), 'new': np.float64(81.1)}\n",
            "2025-12-14 07:56:19,513 [trainer.py] => CNN top1 curve: [np.float64(98.8), np.float64(96.0), np.float64(93.67), np.float64(90.18), np.float64(88.32), np.float64(84.98), np.float64(83.14), np.float64(82.28)]\n",
            "2025-12-14 07:56:19,513 [trainer.py] => CNN top1 with task curve: [np.float64(98.8), np.float64(98.25), np.float64(98.1), np.float64(97.9), np.float64(98.04), np.float64(97.72), np.float64(97.6), np.float64(97.65)]\n",
            "2025-12-14 07:56:19,513 [trainer.py] => CNN top1 task curve: [1.0, 0.972, 0.9473333333333334, 0.9115, 0.8908, 0.8563333333333333, 0.8378571428571429, 0.8285]\n",
            "2025-12-14 07:56:20,822 [trainer.py] => All params: 108610999\n",
            "2025-12-14 07:56:20,825 [trainer.py] => Trainable params: 81418\n",
            "2025-12-14 07:56:20,839 [inflora.py] => Learning on 80-90\n",
            "After enforce: trainable param names count: 26, total trainable elements: 81,418\n",
            "Task 8, Epoch 2/2 => Loss 0.222, Train_accy 92.58: 100% 2/2 [04:48<00:00, 144.05s/it]\n",
            "2025-12-14 08:02:21,313 [inflora.py] => Task 8, Epoch 2/2 => Loss 0.222, Train_accy 92.58\n",
            "Threshold:  1.1500000000000001\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 0/768 type retain\n",
            "Layer 2 : 0/768 type retain\n",
            "Layer 3 : 0/768 type retain\n",
            "Layer 4 : 0/768 type retain\n",
            "Layer 5 : 0/768 type retain\n",
            "Layer 6 : 0/768 type retain\n",
            "Layer 7 : 0/768 type retain\n",
            "Layer 8 : 0/768 type retain\n",
            "Layer 9 : 0/768 type retain\n",
            "Layer 10 : 0/768 type retain\n",
            "Layer 11 : 0/768 type retain\n",
            "Layer 12 : 0/768 type retain\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 6 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 7 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 8 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 9 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 10 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 11 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 12 - Projection Matrix shape: torch.Size([768, 768])\n",
            "2025-12-14 08:04:43,292 [trainer.py] => Time:502.466224193573\n",
            "2025-12-14 08:06:46,806 [trainer.py] => Time:123.51391625404358\n",
            "2025-12-14 08:06:46,806 [inflora.py] => Exemplar size: 0\n",
            "2025-12-14 08:06:46,806 [trainer.py] => CNN: {'total': np.float64(81.12), '00-09': np.float64(94.3), '10-19': np.float64(84.7), '20-29': np.float64(86.9), '30-39': np.float64(78.9), '40-49': np.float64(85.0), '50-59': np.float64(66.4), '60-69': np.float64(73.6), '70-79': np.float64(79.9), '80-89': np.float64(80.4), 'old': np.float64(81.21), 'new': np.float64(80.4)}\n",
            "2025-12-14 08:06:46,807 [trainer.py] => CNN top1 curve: [np.float64(98.8), np.float64(96.0), np.float64(93.67), np.float64(90.18), np.float64(88.32), np.float64(84.98), np.float64(83.14), np.float64(82.28), np.float64(81.12)]\n",
            "2025-12-14 08:06:46,807 [trainer.py] => CNN top1 with task curve: [np.float64(98.8), np.float64(98.25), np.float64(98.1), np.float64(97.9), np.float64(98.04), np.float64(97.72), np.float64(97.6), np.float64(97.65), np.float64(97.5)]\n",
            "2025-12-14 08:06:46,807 [trainer.py] => CNN top1 task curve: [1.0, 0.972, 0.9473333333333334, 0.9115, 0.8908, 0.8563333333333333, 0.8378571428571429, 0.8285, 0.8164444444444444]\n",
            "2025-12-14 08:06:48,088 [trainer.py] => All params: 108766145\n",
            "2025-12-14 08:06:48,090 [trainer.py] => Trainable params: 81418\n",
            "2025-12-14 08:06:48,099 [inflora.py] => Learning on 90-100\n",
            "After enforce: trainable param names count: 26, total trainable elements: 81,418\n",
            "Task 9, Epoch 2/2 => Loss 0.186, Train_accy 94.34: 100% 2/2 [04:48<00:00, 144.31s/it]\n",
            "2025-12-14 08:12:49,349 [inflora.py] => Task 9, Epoch 2/2 => Loss 0.186, Train_accy 94.34\n",
            "Threshold:  1.1750000000000003\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 0/768 type retain\n",
            "Layer 2 : 0/768 type retain\n",
            "Layer 3 : 0/768 type retain\n",
            "Layer 4 : 0/768 type retain\n",
            "Layer 5 : 0/768 type retain\n",
            "Layer 6 : 0/768 type retain\n",
            "Layer 7 : 0/768 type retain\n",
            "Layer 8 : 0/768 type retain\n",
            "Layer 9 : 0/768 type retain\n",
            "Layer 10 : 0/768 type retain\n",
            "Layer 11 : 0/768 type retain\n",
            "Layer 12 : 0/768 type retain\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 6 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 7 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 8 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 9 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 10 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 11 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 12 - Projection Matrix shape: torch.Size([768, 768])\n",
            "2025-12-14 08:15:11,509 [trainer.py] => Time:503.418927192688\n",
            "2025-12-14 08:17:29,269 [trainer.py] => Time:137.7590775489807\n",
            "2025-12-14 08:17:29,269 [inflora.py] => Exemplar size: 0\n",
            "2025-12-14 08:17:29,269 [trainer.py] => CNN: {'total': np.float64(79.47), '00-09': np.float64(93.7), '10-19': np.float64(81.9), '20-29': np.float64(86.3), '30-39': np.float64(76.6), '40-49': np.float64(84.2), '50-59': np.float64(65.0), '60-69': np.float64(72.8), '70-79': np.float64(78.2), '80-89': np.float64(78.4), '90-99': np.float64(77.6), 'old': np.float64(79.68), 'new': np.float64(77.6)}\n",
            "2025-12-14 08:17:29,270 [trainer.py] => CNN top1 curve: [np.float64(98.8), np.float64(96.0), np.float64(93.67), np.float64(90.18), np.float64(88.32), np.float64(84.98), np.float64(83.14), np.float64(82.28), np.float64(81.12), np.float64(79.47)]\n",
            "2025-12-14 08:17:29,270 [trainer.py] => CNN top1 with task curve: [np.float64(98.8), np.float64(98.25), np.float64(98.1), np.float64(97.9), np.float64(98.04), np.float64(97.72), np.float64(97.6), np.float64(97.65), np.float64(97.5), np.float64(97.7)]\n",
            "2025-12-14 08:17:29,270 [trainer.py] => CNN top1 task curve: [1.0, 0.972, 0.9473333333333334, 0.9115, 0.8908, 0.8563333333333333, 0.8378571428571429, 0.8285, 0.8164444444444444, 0.7995]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "mkdir -p /content/drive/MyDrive/datasets/imagenet-r\n",
        "cd /content/drive/MyDrive/datasets\n"
      ],
      "metadata": {
        "id": "BSoYM7se-D2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q huggingface_hub\n"
      ],
      "metadata": {
        "id": "_LSS9Yup-M1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/drive/MyDrive/\n",
        "wget https://people.eecs.berkeley.edu/~hendrycks/imagenet-r.tar\n",
        "tar -xvf imagenet-r.tar\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SGnz1_sF-VUf",
        "outputId": "d5b9695b-a202-4178-d219-3cf51807bec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\", line 211, in shebang\n",
            "    out, err = p.communicate(cell)\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 1209, in communicate\n",
            "    stdout, stderr = self._communicate(input, endtime, timeout)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 2115, in _communicate\n",
            "    ready = selector.select(timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/selectors.py\", line 415, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-1907415161.py\", line 1, in <cell line: 0>\n",
            "    get_ipython().run_cell_magic('bash', '', 'cd /content/drive/MyDrive/\\nwget https://people.eecs.berkeley.edu/~hendrycks/imagenet-r.tar\\ntar -xvf imagenet-r.tar\\n\\n')\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\", line 276, in run_cell_magic\n",
            "    return super().run_cell_magic(magic_name, line, cell)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2473, in run_cell_magic\n",
            "    result = fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\", line 142, in named_script_magic\n",
            "    return self.shebang(line, cell)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<decorator-gen-103>\", line 2, in shebang\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
            "    call = lambda f, *a, **k: f(*a, **k)\n",
            "                              ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\", line 215, in shebang\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1769, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1714, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 970, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1009, in getmodule\n",
            "    if f == _filesbymodname.get(modname, None):\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1907415161.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cd /content/drive/MyDrive/\\nwget https://people.eecs.berkeley.edu/~hendrycks/imagenet-r.tar\\ntar -xvf imagenet-r.tar\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# 在 Colab 的 bash cell 中运行此脚本（确保当前目录为 /content/InfLoRA）\n",
        "cp methods/inflora.py methods/inflora.py.bak2\n",
        "\n",
        "python - <<'PY'\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "p = Path(\"methods/inflora.py\")\n",
        "s = p.read_text()\n",
        "\n",
        "# loose pattern that matches the problematic expression using np.dot(... transpose())\n",
        "pattern = r\"activation\\s*-\\s*np\\.dot\\(\\s*np\\.dot\\(\\s*self\\.feature_list\\[i\\]\\s*,\\s*self\\.feature_list\\[i\\]\\.transpose\\(\\s*\\)\\s*\\)\\s*,\\s*activation\\s*\\)\"\n",
        "\n",
        "if re.search(pattern, s):\n",
        "    replacement = (\n",
        "        \"        # Project activation using PyTorch (robust to numpy/torch types)\\n\"\n",
        "        \"        feat = self.feature_list[i]\\n\"\n",
        "        \"        # Ensure feat is a torch.Tensor\\n\"\n",
        "        \"        if not isinstance(feat, torch.Tensor):\\n\"\n",
        "        \"            feat = torch.as_tensor(feat)\\n\"\n",
        "        \"        # Ensure activation is a torch.Tensor on same device\\n\"\n",
        "        \"        if not isinstance(activation, torch.Tensor):\\n\"\n",
        "        \"            activation = torch.as_tensor(activation, device=feat.device)\\n\"\n",
        "        \"        else:\\n\"\n",
        "        \"            activation = activation.to(feat.device)\\n\"\n",
        "        \"        proj = feat @ feat.T @ activation\\n\"\n",
        "        \"        act_hat = activation - proj\\n\"\n",
        "    )\n",
        "    s_new = re.sub(pattern, replacement, s)\n",
        "    p.write_text(s_new)\n",
        "    print('Replaced matched pattern with PyTorch-safe code.')\n",
        "else:\n",
        "    # Try to catch a slightly different formatting: np.dot(..., self.feature_list[i].transpose())\n",
        "    pattern2 = r\"activation\\s*-\\s*np\\.dot\\(\\s*self\\.feature_list\\[i\\]\\s*,\\s*self\\.feature_list\\[i\\]\\.transpose\\(\\s*\\)\\s*\\)\\s*[,)]\\s*activation?\"\n",
        "    if re.search(pattern2, s):\n",
        "        # This replacement handles the form activation - np.dot(A, A.transpose()).dot(activation) or similar\n",
        "        replacement2 = (\n",
        "            \"        # Project activation using PyTorch (robust to numpy/torch types)\\n\"\n",
        "            \"        feat = self.feature_list[i]\\n\"\n",
        "            \"        if not isinstance(feat, torch.Tensor):\\n\"\n",
        "            \"            feat = torch.as_tensor(feat)\\n\"\n",
        "            \"        if not isinstance(activation, torch.Tensor):\\n\"\n",
        "            \"            activation = torch.as_tensor(activation, device=feat.device)\\n\"\n",
        "            \"        else:\\n\"\n",
        "            \"            activation = activation.to(feat.device)\\n\"\n",
        "            \"        proj = feat @ feat.T @ activation\\n\"\n",
        "            \"        act_hat = activation - proj\\n\"\n",
        "        )\n",
        "        s_new = re.sub(pattern2, replacement2, s)\n",
        "        p.write_text(s_new)\n",
        "        print('Replaced alternate matched pattern with PyTorch-safe code.')\n",
        "    else:\n",
        "        print('No direct pattern found. Showing nearby lines for manual patching:\\\\n')\n",
        "        # Print a few lines around likely area (search for \"update_DualGPM\" function)\n",
        "        idx = s.find(\"def update_DualGPM\")\n",
        "        if idx != -1:\n",
        "            start = max(0, idx - 400)\n",
        "            end = min(len(s), idx + 1400)\n",
        "            print(s[start:end])\n",
        "        else:\n",
        "            print(\"Could not find update_DualGPM function automatically. Please open methods/inflora.py to patch manually.\")\n",
        "\n",
        "# show whether any np.dot(...) or .transpose() usages remain in the file\n",
        "remains_dot = re.findall(r\"np\\.dot\\(\", s_new if 's_new' in locals() else s)\n",
        "remains_trans = re.findall(r\"\\.transpose\\(\", s_new if 's_new' in locals() else s)\n",
        "print(f\"Remaining np.dot occurrences in file: {len(remains_dot)}\")\n",
        "print(f\"Remaining .transpose occurrences in file: {len(remains_trans)}\")\n",
        "\n",
        "# print a short excerpt around the first remaining .transpose if any\n",
        "if len(remains_trans) > 0:\n",
        "    loc = (s_new if 's_new' in locals() else s).find(\".transpose(\")\n",
        "    excerpt_start = max(0, loc-120)\n",
        "    excerpt_end = min(len(s), loc+120)\n",
        "    print(\"Excerpt around first .transpose occurrence:\\\\n\")\n",
        "    print((s_new if 's_new' in locals() else s)[excerpt_start:excerpt_end])\n",
        "PY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X580hELhhAtb",
        "outputId": "a56cd190-9bce-4659-d2bd-052698d0d206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaced matched pattern with PyTorch-safe code.\n",
            "Remaining np.dot occurrences in file: 4\n",
            "Remaining .transpose occurrences in file: 2\n",
            "Excerpt around first .transpose occurrence:\\n\n",
            " # Projected Representation (Eq-8)\n",
            "                    act_hat = np.dot(np.dot(self.feature_list[i],self.feature_list[i].transpose()),activation)\n",
            "                    U,S,Vh = np.linalg.svd(act_hat, full_matrices=False)\n",
            "                    #\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# 备份并自动修补 methods/inflora.py（在 /content/InfLoRA 目录下运行）\n",
        "cp methods/inflora.py methods/inflora.py.bak3\n",
        "\n",
        "python - <<'PY'\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "p = Path(\"methods/inflora.py\")\n",
        "s = p.read_text()\n",
        "\n",
        "# Ensure torch is imported: if not, add `import torch` near top (after other imports)\n",
        "if \"import torch\" not in s:\n",
        "    # try to insert after the first block of imports\n",
        "    lines = s.splitlines()\n",
        "    insert_at = 0\n",
        "    for i, line in enumerate(lines[:60]):\n",
        "        if line.strip().startswith(\"import\") or line.strip().startswith(\"from\"):\n",
        "            insert_at = i+1\n",
        "    lines.insert(insert_at, \"import torch\")\n",
        "    s = \"\\n\".join(lines)\n",
        "    print(\"Inserted 'import torch' near the top of methods/inflora.py\")\n",
        "\n",
        "# 1) Replace .transpose() -> .T (safe for numpy and torch)\n",
        "s = s.replace(\".transpose()\", \".T\")\n",
        "print(\"Replaced '.transpose()' -> '.T' (global)\")\n",
        "\n",
        "# 2) Replace nested np.dot(...) pattern that projects activation:\n",
        "# pattern covers forms like:\n",
        "# act_hat = np.dot(np.dot(self.feature_list[i],self.feature_list[i].T),activation)\n",
        "# or with spaces\n",
        "pattern = re.compile(\n",
        "    r\"act_hat\\s*=\\s*np\\.dot\\(\\s*np\\.dot\\(\\s*(self\\.feature_list\\[(?P<idx>[^\\]]+)\\])\\s*,\\s*(self\\.feature_list\\[\\s*(?P=idx)\\s*\\]\\.T)\\s*\\)\\s*,\\s*(?P<act>\\w+)\\s*\\)\"\n",
        ")\n",
        "def repl_proj(m):\n",
        "    idx = m.group('idx')\n",
        "    act = m.group('act')\n",
        "    code = (\n",
        "        f\"        # Projected Representation (converted to PyTorch operations)\\n\"\n",
        "        f\"        feat = {m.group(1)}\\n\"\n",
        "        f\"        # Ensure feat is a torch.Tensor on device\\n\"\n",
        "        f\"        if not isinstance(feat, torch.Tensor):\\n\"\n",
        "        f\"            feat = torch.as_tensor(feat)\\n\"\n",
        "        f\"        # Ensure activation is a torch.Tensor on same device\\n\"\n",
        "        f\"        if not isinstance({act}, torch.Tensor):\\n\"\n",
        "        f\"            {act} = torch.as_tensor({act}, device=feat.device)\\n\"\n",
        "        f\"        else:\\n\"\n",
        "        f\"            {act} = {act}.to(feat.device)\\n\"\n",
        "        f\"        proj = feat @ feat.T @ {act}\\n\"\n",
        "        f\"        act_hat = {act} - proj\\n\"\n",
        "    )\n",
        "    return code\n",
        "\n",
        "s_new = pattern.sub(repl_proj, s)\n",
        "if s_new != s:\n",
        "    s = s_new\n",
        "    print(\"Replaced nested np.dot(... .T ...) projection pattern with PyTorch-safe code.\")\n",
        "else:\n",
        "    print(\"No nested np.dot projection pattern found by regex. (Maybe different formatting)\")\n",
        "\n",
        "# 3) Replace any remaining simpler pattern variants like:\n",
        "# act_hat = np.dot(self.feature_list[i] @ self.feature_list[i].T, activation) or similar\n",
        "# We'll search for occurrences of \"np.dot(\" with feature_list and replace with explicit tensor ops near them.\n",
        "simple_pattern = re.compile(\n",
        "    r\"(?P<indent>\\s*)act_hat\\s*=\\s*np\\.dot\\(\\s*(self\\.feature_list\\[(?P<idx2>[^\\]]+)\\]\\.T?\\s*|\\s*self\\.feature_list\\[(?P=idx2)\\])\\s*,\\s*(?P<act2>\\w+)\\s*\\)\"\n",
        ")\n",
        "def repl_simple(m):\n",
        "    idx = m.group('idx2')\n",
        "    act = m.group('act2')\n",
        "    indent = m.group('indent')\n",
        "    code = (\n",
        "        f\"{indent}# Converted simple np.dot projection to PyTorch\\n\"\n",
        "        f\"{indent}feat = self.feature_list[{idx}]\\n\"\n",
        "        f\"{indent}if not isinstance(feat, torch.Tensor):\\n\"\n",
        "        f\"{indent}    feat = torch.as_tensor(feat)\\n\"\n",
        "        f\"{indent}if not isinstance({act}, torch.Tensor):\\n\"\n",
        "        f\"{indent}    {act} = torch.as_tensor({act}, device=feat.device)\\n\"\n",
        "        f\"{indent}else:\\n\"\n",
        "        f\"{indent}    {act} = {act}.to(feat.device)\\n\"\n",
        "        f\"{indent}proj = feat @ feat.T @ {act}\\n\"\n",
        "        f\"{indent}act_hat = {act} - proj\\n\"\n",
        "    )\n",
        "    return code\n",
        "\n",
        "s_new = simple_pattern.sub(repl_simple, s)\n",
        "if s_new != s:\n",
        "    s = s_new\n",
        "    print(\"Replaced simpler np.dot projection occurrences.\")\n",
        "else:\n",
        "    print(\"No simpler np.dot projection occurrences replaced by this pass.\")\n",
        "\n",
        "# 4) Replace np.linalg.svd(...) -> torch.linalg.svd(...), with tensor guard\n",
        "svd_pattern = re.compile(r\"(?P<indent>\\s*)U\\s*,\\s*S\\s*,\\s*Vh\\s*=\\s*np\\.linalg\\.svd\\(\\s*(?P<arg>\\w+)\\s*,\\s*full_matrices\\s*=\\s*False\\s*\\)\")\n",
        "def repl_svd(m):\n",
        "    indent = m.group('indent')\n",
        "    arg = m.group('arg')\n",
        "    code = (\n",
        "        f\"{indent}# Use PyTorch SVD for tensor compatibility\\n\"\n",
        "        f\"{indent}if not isinstance({arg}, torch.Tensor):\\n\"\n",
        "        f\"{indent}    {arg} = torch.as_tensor({arg})\\n\"\n",
        "        f\"{indent}# Try moving to same device as feat if feat exists\\n\"\n",
        "        f\"{indent}try:\\n\"\n",
        "        f\"{indent}    {arg} = {arg}.to(feat.device)\\n\"\n",
        "        f\"{indent}except Exception:\\n\"\n",
        "        f\"{indent}    pass\\n\"\n",
        "        f\"{indent}U, S, Vh = torch.linalg.svd({arg}, full_matrices=False)\\n\"\n",
        "    )\n",
        "    return code\n",
        "\n",
        "s_new = svd_pattern.sub(repl_svd, s)\n",
        "if s_new != s:\n",
        "    s = s_new\n",
        "    print(\"Replaced np.linalg.svd(...) with torch.linalg.svd(...) and added tensor guards.\")\n",
        "else:\n",
        "    print(\"No exact np.linalg.svd(...) pattern found for replacement. Trying broader match...\")\n",
        "\n",
        "# broader match for np.linalg.svd occurrences\n",
        "if \"np.linalg.svd\" in s:\n",
        "    s = s.replace(\"np.linalg.svd(\", \"torch.linalg.svd(\")\n",
        "    print(\"Replaced remaining 'np.linalg.svd(' -> 'torch.linalg.svd(' (note: may need device guards).\")\n",
        "\n",
        "# write back\n",
        "p.write_text(s)\n",
        "print(\"Wrote patched methods/inflora.py\")\n",
        "\n",
        "# Report remaining np.dot and .transpose occurrences for manual review\n",
        "remains_dot = len(re.findall(r\"np\\.dot\\(\", s))\n",
        "remains_transpose_calls = len(re.findall(r\"\\.transpose\\(\", s))\n",
        "remains_T_attrs = len(re.findall(r\"\\.T\\b\", s))  # occurrences of .T\n",
        "print(f\"Remaining np.dot occurrences: {remains_dot}\")\n",
        "print(f\"Remaining .transpose(...) calls: {remains_transpose_calls}\")\n",
        "print(f\"Occurrences of .T in file (should exist where .transpose replaced): {remains_T_attrs}\")\n",
        "\n",
        "# show excerpt around first occurrence of torch.linalg.svd if any\n",
        "loc = s.find(\"torch.linalg.svd\")\n",
        "if loc != -1:\n",
        "    start = max(0, loc-120)\n",
        "    end = min(len(s), loc+240)\n",
        "    print(\"\\\\nExcerpt around first torch.linalg.svd occurrence:\\\\n\")\n",
        "    print(s[start:end])\n",
        "else:\n",
        "    print(\"\\\\nNo torch.linalg.svd occurrences found in file after replacement.\")\n",
        "PY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdWP9vFehVXV",
        "outputId": "7593476c-d358-4dfd-83d2-afc5ad236f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaced '.transpose()' -> '.T' (global)\n",
            "Replaced nested np.dot(... .T ...) projection pattern with PyTorch-safe code.\n",
            "No simpler np.dot projection occurrences replaced by this pass.\n",
            "Replaced np.linalg.svd(...) with torch.linalg.svd(...) and added tensor guards.\n",
            "Replaced remaining 'np.linalg.svd(' -> 'torch.linalg.svd(' (note: may need device guards).\n",
            "Wrote patched methods/inflora.py\n",
            "Remaining np.dot occurrences: 2\n",
            "Remaining .transpose(...) calls: 0\n",
            "Occurrences of .T in file (should exist where .transpose replaced): 11\n",
            "\\nExcerpt around first torch.linalg.svd occurrence:\\n\n",
            "tance(module, Attention_LoRA):\n",
            "                        cur_matrix = module.cur_matrix\n",
            "                        U, S, V = torch.linalg.svd(cur_matrix)\n",
            "                        module.lora_A_k[self._cur_task].weight.data.copy_(U[:,:module.rank].T/math.sqrt(3))\n",
            "                        module.lora_A_v[self._cur_task].weight.data.copy_(U[:,:module.rank].T/math.sqrt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# 在仓库根目录 /content/InfLoRA 下运行\n",
        "cp methods/inflora.py methods/inflora.py.bak4\n",
        "\n",
        "python - <<'PY'\n",
        "from pathlib import Path\n",
        "import re\n",
        "p = Path(\"methods/inflora.py\")\n",
        "s = p.read_text()\n",
        "\n",
        "# Ensure numpy and torch imports exist\n",
        "if \"import numpy as np\" not in s:\n",
        "    # Try to insert near imports\n",
        "    lines = s.splitlines()\n",
        "    insert_at = 0\n",
        "    for i, line in enumerate(lines[:80]):\n",
        "        if line.strip().startswith(\"import\") or line.strip().startswith(\"from\"):\n",
        "            insert_at = i+1\n",
        "    lines.insert(insert_at, \"import numpy as np\")\n",
        "    s = \"\\n\".join(lines)\n",
        "    print(\"Inserted 'import numpy as np' near top of file.\")\n",
        "\n",
        "if \"import torch\" not in s:\n",
        "    lines = s.splitlines()\n",
        "    insert_at = 0\n",
        "    for i, line in enumerate(lines[:80]):\n",
        "        if line.strip().startswith(\"import\") or line.strip().startswith(\"from\"):\n",
        "            insert_at = i+1\n",
        "    lines.insert(insert_at, \"import torch\")\n",
        "    s = \"\\n\".join(lines)\n",
        "    print(\"Inserted 'import torch' near top of file.\")\n",
        "\n",
        "# Insert helper function _matmul(a,b) if not present\n",
        "if \"_matmul(\" not in s:\n",
        "    helper = \"\"\"\n",
        "# Helper: safe matrix multiply that accepts numpy arrays or torch tensors and returns a torch.Tensor on correct device\n",
        "def _matmul(a, b):\n",
        "    # Prefer torch tensors for computation\n",
        "    # If inputs are numpy arrays, convert them. If inputs are torch tensors, ensure they are on same device.\n",
        "    if isinstance(a, np.ndarray):\n",
        "        a = torch.as_tensor(a)\n",
        "    if isinstance(b, np.ndarray):\n",
        "        # If 'a' is already a tensor, put 'b' on same device; else let torch decide\n",
        "        try:\n",
        "            b = torch.as_tensor(b, device=a.device)\n",
        "        except Exception:\n",
        "            b = torch.as_tensor(b)\n",
        "    # Finally ensure both are torch tensors\n",
        "    if not isinstance(a, torch.Tensor):\n",
        "        a = torch.as_tensor(a)\n",
        "    if not isinstance(b, torch.Tensor):\n",
        "        # place b on same device as a if possible\n",
        "        try:\n",
        "            b = torch.as_tensor(b, device=a.device)\n",
        "        except Exception:\n",
        "            b = torch.as_tensor(b)\n",
        "    # Use @ for matrix multiplication (works for 1D/2D appropriately like np.dot)\n",
        "    return a @ b\n",
        "\n",
        "\"\"\"\n",
        "    # insert helper after imports block (find last import line)\n",
        "    lines = s.splitlines()\n",
        "    last_import_idx = 0\n",
        "    for i, line in enumerate(lines[:200]):\n",
        "        if line.strip().startswith(\"import\") or line.strip().startswith(\"from\"):\n",
        "            last_import_idx = i\n",
        "    # insert after a small offset\n",
        "    insert_pos = last_import_idx + 1\n",
        "    lines.insert(insert_pos, helper)\n",
        "    s = \"\\n\".join(lines)\n",
        "    print(\"Inserted helper function _matmul into methods/inflora.py\")\n",
        "\n",
        "# Replace all occurrences of np.dot( with _matmul(\n",
        "count_before = len(re.findall(r\"np\\.dot\\(\", s))\n",
        "s_replaced = s.replace(\"np.dot(\", \"_matmul(\")\n",
        "count_after = len(re.findall(r\"np\\.dot\\(\", s_replaced))\n",
        "replacements = count_before - count_after\n",
        "\n",
        "p.write_text(s_replaced)\n",
        "print(f\"Replaced {replacements} occurrences of 'np.dot(' with '_matmul(' (before: {count_before}, after: {count_after})\")\n",
        "\n",
        "# Report remaining np.dot occurrences and show contexts\n",
        "remains_dot = list(re.finditer(r\"_matmul\\(\", s_replaced))\n",
        "print(f\"Occurrences of new '_matmul(' in file: {len(remains_dot)}\")\n",
        "for i, m in enumerate(remains_dot[:10]):\n",
        "    start = m.start()\n",
        "    excerpt_start = max(0, start-120)\n",
        "    excerpt_end = min(len(s_replaced), start+120)\n",
        "    print(f\"--- occurrence {i+1} context ---\")\n",
        "    print(s_replaced[excerpt_start:excerpt_end])\n",
        "    print(\"----------------------------\")\n",
        "\n",
        "# Also show if any np.dot remains\n",
        "rem_npdot = len(re.findall(r\"np\\.dot\\(\", s_replaced))\n",
        "print(\"Remaining literal 'np.dot(' occurrences after replacement:\", rem_npdot)\n",
        "\n",
        "# Quick check: any .transpose( left?\n",
        "rem_transpose = len(re.findall(r\"\\.transpose\\(\", s_replaced))\n",
        "print(\"Remaining '.transpose(' calls:\", rem_transpose)\n",
        "\n",
        "# Save final file (already written)\n",
        "print(\"Patched file written to methods/inflora.py; backup at methods/inflora.py.bak4\")\n",
        "PY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07LFdzslhnQo",
        "outputId": "75e879d5-dd3c-4729-b150-a83227dcd007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted helper function _matmul into methods/inflora.py\n",
            "Replaced 2 occurrences of 'np.dot(' with '_matmul(' (before: 2, after: 0)\n",
            "Occurrences of new '_matmul(' in file: 3\n",
            "--- occurrence 1 context ---\n",
            "elper: safe matrix multiply that accepts numpy arrays or torch tensors and returns a torch.Tensor on correct device\n",
            "def _matmul(a, b):\n",
            "    # Prefer torch tensors for computation\n",
            "    # If inputs are numpy arrays, convert them. If inputs are \n",
            "----------------------------\n",
            "--- occurrence 2 context ---\n",
            "               # update GPM by Projected Representation (Eq-8)\n",
            "                    act_feature = self.feature_list[i] - _matmul(_matmul(U[:,0:r],U[:,0:r].T),self.feature_list[i])\n",
            "                    Ui, Si, Vi = torch.linalg.svd(act_feature\n",
            "----------------------------\n",
            "--- occurrence 3 context ---\n",
            "       # update GPM by Projected Representation (Eq-8)\n",
            "                    act_feature = self.feature_list[i] - _matmul(_matmul(U[:,0:r],U[:,0:r].T),self.feature_list[i])\n",
            "                    Ui, Si, Vi = torch.linalg.svd(act_feature)\n",
            "      \n",
            "----------------------------\n",
            "Remaining literal 'np.dot(' occurrences after replacement: 0\n",
            "Remaining '.transpose(' calls: 0\n",
            "Patched file written to methods/inflora.py; backup at methods/inflora.py.bak4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --device 0 --config configs/cifar100_inflora_debug.json 2>&1 | tee /content/inflora_debug_run.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfuCoqZniFOH",
        "outputId": "a0cd0d56-b223-43a1-edc5-45ae01d94e18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/InfLoRA/main.py\", line 3, in <module>\n",
            "    from trainer import train\n",
            "  File \"/content/InfLoRA/trainer.py\", line 8, in <module>\n",
            "    from utils import factory\n",
            "  File \"/content/InfLoRA/utils/factory.py\", line 4, in <module>\n",
            "    from methods.inflora import InfLoRA\n",
            "  File \"/content/InfLoRA/methods/inflora.py\", line 389\n",
            "    act_hat =         # Project activation using PyTorch (robust to numpy/torch types)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "SyntaxError: invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cp methods/inflora.py methods/inflora.py.bak_fix_syntax\n",
        "\n",
        "python - <<'PY'\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "path = Path(\"methods/inflora.py\")\n",
        "code = path.read_text()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# PATCH 1: 修复 update_DualGPM 的 act_hat block\n",
        "# ---------------------------------------------------------\n",
        "dual_block_pattern = r\"\"\"\n",
        "act_hat\\s*=.*?  #\\s*Project activation[\\s\\S]*?  # 注意，这里的注释 block 有可能被损坏\n",
        "\"\"\"\n",
        "\n",
        "# 用一个严格正确的版本替换\n",
        "dual_block_replacement = \"\"\"\n",
        "        # Project activation using PyTorch (robust to numpy/torch types)\n",
        "        feat = self.feature_list[i]\n",
        "        if isinstance(feat, np.ndarray):\n",
        "            feat = torch.as_tensor(feat)\n",
        "\n",
        "        if not isinstance(activation, torch.Tensor):\n",
        "            activation = torch.as_tensor(activation, device=feat.device)\n",
        "        else:\n",
        "            activation = activation.to(feat.device)\n",
        "\n",
        "        proj = _matmul(_matmul(feat, feat.T), activation)\n",
        "        act_hat = activation - proj\n",
        "\"\"\"\n",
        "\n",
        "# 宽松替换：匹配行首有 act_hat = 的投影段\n",
        "code = re.sub(r\"act_hat\\s*=.*\", dual_block_replacement, code)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# PATCH 2: 修复 update_GPM 中 act_feature 块\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "gpm_block_pattern = r\"act_feature\\s*=.*\"\n",
        "gpm_block_replacement = \"\"\"\n",
        "                    # Projected Representation (Eq-8)\n",
        "                    act_feature = self.feature_list[i] - _matmul(_matmul(U[:, :r], U[:, :r].T), self.feature_list[i])\n",
        "\"\"\"\n",
        "\n",
        "code = re.sub(gpm_block_pattern, gpm_block_replacement, code)\n",
        "\n",
        "\n",
        "# 写回文件\n",
        "path.write_text(code)\n",
        "print(\"Patched syntax and projection blocks successfully.\")\n",
        "print(\"Backup: methods/inflora.py.bak_fix_syntax\")\n",
        "PY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk_oxm_6iUWQ",
        "outputId": "89bbcdd1-7ba0-478b-dd57-1b5ae4127b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patched syntax and projection blocks successfully.\n",
            "Backup: methods/inflora.py.bak_fix_syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --device 0 --config configs/cifar100_inflora_debug.json 2>&1 | tee /content/inflora_debug_run.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myWoAXccibTU",
        "outputId": "2065929c-7f72-496c-ae41-5d6d70ab3e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/InfLoRA/main.py\", line 3, in <module>\n",
            "    from trainer import train\n",
            "  File \"/content/InfLoRA/trainer.py\", line 8, in <module>\n",
            "    from utils import factory\n",
            "  File \"/content/InfLoRA/utils/factory.py\", line 4, in <module>\n",
            "    from methods.inflora import InfLoRA\n",
            "  File \"/content/InfLoRA/methods/inflora.py\", line 431\n",
            "    if not isinstance(act_hat, torch.Tensor):\n",
            "IndentationError: unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# 备份并修复 methods/inflora.py 的 act_hat/proj 区块（在 /content/InfLoRA 下运行）\n",
        "cp methods/inflora.py methods/inflora.py.bak5\n",
        "\n",
        "python - <<'PY'\n",
        "from pathlib import Path\n",
        "import re\n",
        "p = Path(\"methods/inflora.py\")\n",
        "s = p.read_text()\n",
        "\n",
        "# We'll replace any block that includes 'proj = ' and 'act_hat =' (spanning multiple lines)\n",
        "# with a correctly indented, robust implementation.\n",
        "pattern = re.compile(\n",
        "    r\"(?P<indent>[\\t ]*)(?:#.*\\n\\s*)*proj\\s*=.*?\\n\\s*act_hat\\s*=.*?(?:\\n|$)\",\n",
        "    re.S\n",
        ")\n",
        "\n",
        "replacement_template = (\n",
        "    \"{indent}# Compute projection and ensure tensor/device consistency\\n\"\n",
        "    \"{indent}proj = _matmul(_matmul(feat, feat.T), activation)\\n\"\n",
        "    \"{indent}act_hat = activation - proj\\n\"\n",
        "    \"{indent}# Ensure act_hat is a torch.Tensor on the same device as feat\\n\"\n",
        "    \"{indent}if not isinstance(act_hat, torch.Tensor):\\n\"\n",
        "    \"{indent}    act_hat = torch.as_tensor(act_hat, device=feat.device)\\n\"\n",
        "    \"{indent}else:\\n\"\n",
        "    \"{indent}    act_hat = act_hat.to(feat.device)\\n\"\n",
        ")\n",
        "\n",
        "replacements = 0\n",
        "def repl(m):\n",
        "    global replacements\n",
        "    indent = m.group('indent') or \"\"\n",
        "    replacements += 1\n",
        "    return replacement_template.format(indent=indent)\n",
        "\n",
        "s_new = pattern.sub(repl, s)\n",
        "\n",
        "if replacements == 0:\n",
        "    # If no proj/act_hat block matched, try to match 'act_hat =' alone and replace surrounding lines conservatively\n",
        "    pattern2 = re.compile(r\"(?P<indent>[\\t ]*)act_hat\\s*=.*?(?:\\n|$)\", re.S)\n",
        "    s_new2 = pattern2.sub(lambda m: replacement_template.format(indent=m.group('indent') or \"\"), s)\n",
        "    if s_new2 != s:\n",
        "        s_new = s_new2\n",
        "        replacements = len(re.findall(r\"act_hat\\s*=\", s_new))\n",
        "        print(f\"No proj-block matches; replaced {replacements} 'act_hat =' occurrences with canonical block.\")\n",
        "    else:\n",
        "        print(\"No obvious 'proj'/'act_hat' blocks found by the script. Showing a short excerpt around line 400-460 for manual inspection:\")\n",
        "        start = 3800 if len(s) > 3800 else 0\n",
        "        print(s[start:start+1500])\n",
        "        # write no-change file (keep backup only)\n",
        "        p.write_text(s)\n",
        "        raise SystemExit(\"No automatic replacements performed.\")\n",
        "\n",
        "# Write patched file\n",
        "p.write_text(s_new)\n",
        "print(f\"Patched {replacements} proj/act_hat block(s) in methods/inflora.py (backup at methods/inflora.py.bak5).\")\n",
        "\n",
        "# Show context around first occurrence for verification\n",
        "loc = s_new.find(\"act_hat\")\n",
        "if loc != -1:\n",
        "    start = max(0, loc-200)\n",
        "    end = min(len(s_new), loc+400)\n",
        "    print(\"\\\\nExcerpt around first 'act_hat' after patch:\\\\n\")\n",
        "    print(s_new[start:end])\n",
        "else:\n",
        "    print(\"No 'act_hat' found after patch (unexpected).\")\n",
        "PY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcoawiYjirHD",
        "outputId": "31cd6e74-b1fe-4283-f2bb-808af7d4b654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patched 1 proj/act_hat block(s) in methods/inflora.py (backup at methods/inflora.py.bak5).\n",
            "\\nExcerpt around first 'act_hat' after patch:\\n\n",
            "m copy import deepcopy\n",
            "from utils.schedulers import CosineSchedule\n",
            "import ipdb\n",
            "import math\n",
            "\n",
            "# Compute projection and ensure tensor/device consistency\n",
            "proj = _matmul(_matmul(feat, feat.T), activation)\n",
            "act_hat = activation - proj\n",
            "# Ensure act_hat is a torch.Tensor on the same device as feat\n",
            "if not isinstance(act_hat, torch.Tensor):\n",
            "    act_hat = torch.as_tensor(act_hat, device=feat.device)\n",
            "else:\n",
            "    act_hat = act_hat.to(feat.device)\n",
            "\n",
            "\n",
            "\n",
            "                except Exception:\n",
            "\n",
            "\n",
            "                    pass\n",
            "\n",
            "\n",
            "                U, S, Vh = torch.linalg.svd(act_hat, full_matrices=False)\n",
            "\n",
            "                # criter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --device 0 --config configs/cifar100_inflora_debug.json 2>&1 | tee /content/inflora_debug_run.log\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG-EzxLqi4DA",
        "outputId": "3c8e8a91-1b03-4ca7-a2b7-b12ba8365597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/InfLoRA/main.py\", line 3, in <module>\n",
            "    from trainer import train\n",
            "  File \"/content/InfLoRA/trainer.py\", line 8, in <module>\n",
            "    from utils import factory\n",
            "  File \"/content/InfLoRA/utils/factory.py\", line 4, in <module>\n",
            "    from methods.inflora import InfLoRA\n",
            "  File \"/content/InfLoRA/methods/inflora.py\", line 32\n",
            "    except Exception:\n",
            "IndentationError: unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# 确保在仓库根目录\n",
        "pwd\n",
        "ls -la methods/inflora.py*\n",
        "echo \"---- git status (to see uncommitted changes) ----\"\n",
        "git status --porcelain || true\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atSBbPDwjUr5",
        "outputId": "3201518e-fb53-489b-a0f5-e09e140ea4bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/InfLoRA\n",
            "-rw-r--r-- 1 root root  2154 Dec  4 08:46 methods/inflora.py\n",
            "-rw-r--r-- 1 root root 21614 Dec  4 08:14 methods/inflora.py.bak\n",
            "-rw-r--r-- 1 root root 21586 Dec  4 08:39 methods/inflora.py.bak2\n",
            "-rw-r--r-- 1 root root 22536 Dec  4 08:41 methods/inflora.py.bak3\n",
            "-rw-r--r-- 1 root root 25078 Dec  4 08:43 methods/inflora.py.bak4\n",
            "-rw-r--r-- 1 root root 31023 Dec  4 08:46 methods/inflora.py.bak5\n",
            "-rw-r--r-- 1 root root 26111 Dec  4 08:45 methods/inflora.py.bak_fix_syntax\n",
            "---- git status (to see uncommitted changes) ----\n",
            " M logs/cifar100/10_10_sip/InfLoRA/adam/10/0.95_1.0-0.0005/0.log\n",
            " M methods/inflora.py\n",
            "?? __pycache__/trainer.cpython-312.pyc\n",
            "?? configs/cifar100_inflora_debug.json\n",
            "?? data/\n",
            "?? logs/cifar100/10_10_sip/InfLoRA/adam/4/\n",
            "?? methods/__pycache__/__init__.cpython-312.pyc\n",
            "?? methods/__pycache__/base.cpython-312.pyc\n",
            "?? methods/__pycache__/inflora.cpython-312.pyc\n",
            "?? methods/__pycache__/inflora_ca.cpython-312.pyc\n",
            "?? methods/__pycache__/inflora_ca1.cpython-312.pyc\n",
            "?? methods/__pycache__/inflora_domain.cpython-312.pyc\n",
            "?? methods/__pycache__/inflorab5.cpython-312.pyc\n",
            "?? methods/__pycache__/inflorab5_domain.cpython-312.pyc\n",
            "?? methods/__pycache__/sprompt_coda.cpython-312.pyc\n",
            "?? methods/__pycache__/sprompt_dual.cpython-312.pyc\n",
            "?? methods/__pycache__/sprompt_l2p.cpython-312.pyc\n",
            "?? methods/inflora.py.bak\n",
            "?? methods/inflora.py.bak2\n",
            "?? methods/inflora.py.bak3\n",
            "?? methods/inflora.py.bak4\n",
            "?? methods/inflora.py.bak5\n",
            "?? methods/inflora.py.bak_fix_syntax\n",
            "?? models/__pycache__/__init__.cpython-312.pyc\n",
            "?? models/__pycache__/sinet_coda.cpython-312.pyc\n",
            "?? models/__pycache__/sinet_dual.cpython-312.pyc\n",
            "?? models/__pycache__/sinet_inflora.cpython-312.pyc\n",
            "?? models/__pycache__/sinet_inflorab5.cpython-312.pyc\n",
            "?? models/__pycache__/sinet_l2p.cpython-312.pyc\n",
            "?? models/__pycache__/vit.cpython-312.pyc\n",
            "?? models/__pycache__/vit_inflora.cpython-312.pyc\n",
            "?? models/__pycache__/vit_inflorab5.cpython-312.pyc\n",
            "?? models/__pycache__/zoo.cpython-312.pyc\n",
            "?? utils/__pycache__/__init__.cpython-312.pyc\n",
            "?? utils/__pycache__/data.cpython-312.pyc\n",
            "?? utils/__pycache__/data_manager.cpython-312.pyc\n",
            "?? utils/__pycache__/factory.cpython-312.pyc\n",
            "?? utils/__pycache__/schedulers.cpython-312.pyc\n",
            "?? utils/__pycache__/toolkit.cpython-312.pyc\n",
            "?? utils/datautils/__pycache__/core50data.cpython-312.pyc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# 示例：如果存在 methods/inflora.py.bak（最早的备份），用它覆盖当前文件\n",
        "cp methods/inflora.py.bak methods/inflora.py\n",
        "echo \"Restored from methods/inflora.py.bak\"\n",
        "\n",
        "# 如果没有 .bak 而只有 .bak2/.bak3，可以逐一尝试\n",
        "# cp methods/inflora.py.bak2 methods/inflora.py\n",
        "# cp methods/inflora.py.bak3 methods/inflora.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSUkexJIjh-n",
        "outputId": "c9d44774-17ce-4fbd-e593-bf73b09f20fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored from methods/inflora.py.bak\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --device 0 --config configs/cifar100_inflora_debug.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC9qluJemt31",
        "outputId": "d4f51d43-055e-4d83-a505-360fffce483f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logs/cifar100/10_10_sip/InfLoRA/adam/4/0.95_1.0-0.0005/0\n",
            "2025-12-04 09:04:33,478 [trainer.py] => config: configs/cifar100_inflora_debug.json\n",
            "2025-12-04 09:04:33,478 [trainer.py] => device: [device(type='cuda', index=0)]\n",
            "2025-12-04 09:04:33,478 [trainer.py] => prefix: reproduce_debug\n",
            "2025-12-04 09:04:33,478 [trainer.py] => dataset: cifar100\n",
            "2025-12-04 09:04:33,478 [trainer.py] => data_path: data/\n",
            "2025-12-04 09:04:33,478 [trainer.py] => memory_size: 0\n",
            "2025-12-04 09:04:33,478 [trainer.py] => memory_per_class: 0\n",
            "2025-12-04 09:04:33,479 [trainer.py] => fixed_memory: True\n",
            "2025-12-04 09:04:33,479 [trainer.py] => shuffle: False\n",
            "2025-12-04 09:04:33,479 [trainer.py] => init_cls: 10\n",
            "2025-12-04 09:04:33,479 [trainer.py] => increment: 10\n",
            "2025-12-04 09:04:33,479 [trainer.py] => total_sessions: 2\n",
            "2025-12-04 09:04:33,479 [trainer.py] => model_name: InfLoRA\n",
            "2025-12-04 09:04:33,479 [trainer.py] => net_type: sip\n",
            "2025-12-04 09:04:33,479 [trainer.py] => embd_dim: 768\n",
            "2025-12-04 09:04:33,479 [trainer.py] => num_heads: 12\n",
            "2025-12-04 09:04:33,479 [trainer.py] => seed: 0\n",
            "2025-12-04 09:04:33,479 [trainer.py] => EPSILON: 1e-08\n",
            "2025-12-04 09:04:33,479 [trainer.py] => init_epoch: 2\n",
            "2025-12-04 09:04:33,479 [trainer.py] => optim: adam\n",
            "2025-12-04 09:04:33,479 [trainer.py] => init_lr: 0.0005\n",
            "2025-12-04 09:04:33,480 [trainer.py] => init_lr_decay: 0.1\n",
            "2025-12-04 09:04:33,480 [trainer.py] => init_weight_decay: 0.0\n",
            "2025-12-04 09:04:33,480 [trainer.py] => epochs: 2\n",
            "2025-12-04 09:04:33,480 [trainer.py] => lrate: 0.0005\n",
            "2025-12-04 09:04:33,480 [trainer.py] => lrate_decay: 0.1\n",
            "2025-12-04 09:04:33,480 [trainer.py] => batch_size: 32\n",
            "2025-12-04 09:04:33,480 [trainer.py] => weight_decay: 0.0\n",
            "2025-12-04 09:04:33,480 [trainer.py] => rank: 4\n",
            "2025-12-04 09:04:33,480 [trainer.py] => lamb: 0.95\n",
            "2025-12-04 09:04:33,480 [trainer.py] => lame: 1.0\n",
            "2025-12-04 09:04:33,480 [trainer.py] => num_workers: 2\n",
            "2025-12-04 09:04:35,196 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "2025-12-04 09:04:37,638 [trainer.py] => All params: 107680123\n",
            "2025-12-04 09:04:37,638 [trainer.py] => Trainable params: 107680123\n",
            "2025-12-04 09:04:37,639 [inflora.py] => Learning on 0-10\n",
            "Parameters to be updated: {'classifier_pool.0.weight', 'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight'}\n",
            "Task 0, Epoch 2/2 => Loss 0.190, Train_accy 93.76: 100% 2/2 [05:09<00:00, 154.73s/it]\n",
            "2025-12-04 09:10:56,290 [inflora.py] => Task 0, Epoch 2/2 => Loss 0.190, Train_accy 93.76\n",
            "Threshold:  0.95\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 6/768 type remove\n",
            "Layer 2 : 9/768 type remove\n",
            "Layer 3 : 11/768 type remove\n",
            "Layer 4 : 10/768 type remove\n",
            "Layer 5 : 11/768 type remove\n",
            "Layer 6 : 13/768 type remove\n",
            "Layer 7 : 12/768 type remove\n",
            "Layer 8 : 16/768 type remove\n",
            "Layer 9 : 17/768 type remove\n",
            "Layer 10 : 14/768 type remove\n",
            "Layer 11 : 5/768 type remove\n",
            "Layer 12 : 9/768 type remove\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 6 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 7 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 8 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 9 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 10 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 11 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 12 - Projection Matrix shape: torch.Size([768, 768])\n",
            "2025-12-04 09:13:26,826 [trainer.py] => Time:529.1875319480896\n",
            "1000 1000\n",
            "1000 1000\n",
            "2025-12-04 09:13:41,625 [trainer.py] => Time:14.798910140991211\n",
            "2025-12-04 09:13:41,626 [inflora.py] => Exemplar size: 0\n",
            "2025-12-04 09:13:41,626 [trainer.py] => CNN: {'total': np.float64(98.9), '00-09': np.float64(98.9), 'old': 0, 'new': np.float64(98.9)}\n",
            "2025-12-04 09:13:41,626 [trainer.py] => CNN top1 curve: [np.float64(98.9)]\n",
            "2025-12-04 09:13:41,626 [trainer.py] => CNN top1 with task curve: [np.float64(98.9)]\n",
            "2025-12-04 09:13:41,626 [trainer.py] => CNN top1 task curve: [1.0]\n",
            "2025-12-04 09:13:43,579 [trainer.py] => All params: 107680123\n",
            "2025-12-04 09:13:43,580 [trainer.py] => Trainable params: 81418\n",
            "2025-12-04 09:13:43,581 [inflora.py] => Learning on 10-20\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/InfLoRA/main.py\", line 33, in <module>\n",
            "    main()\n",
            "  File \"/content/InfLoRA/main.py\", line 11, in main\n",
            "    train(args)\n",
            "  File \"/content/InfLoRA/trainer.py\", line 21, in train\n",
            "    _train(args)\n",
            "  File \"/content/InfLoRA/trainer.py\", line 62, in _train\n",
            "    model.incremental_train(data_manager)\n",
            "  File \"/content/InfLoRA/methods/inflora.py\", line 134, in incremental_train\n",
            "    self._train(self.train_loader, self.test_loader)\n",
            "  File \"/content/InfLoRA/methods/inflora.py\", line 188, in _train\n",
            "    cur_matrix = cur_matrix - torch.mm(self.feature_mat[kk], cur_matrix)\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Expected all tensors to be on the same device, but got mat2 is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA_mm)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python main.py --device 0 --config configs/cifar100_inflora_debug.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjdB1iFzqU2b",
        "outputId": "e04bd024-e1c6-4ee0-f4ef-7986ff9a2ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logs/cifar100/10_10_sip/InfLoRA/adam/4/0.95_1.0-0.0005/0\n",
            "2025-12-04 09:26:42,044 [trainer.py] => config: configs/cifar100_inflora_debug.json\n",
            "2025-12-04 09:26:42,044 [trainer.py] => device: [device(type='cuda', index=0)]\n",
            "2025-12-04 09:26:42,044 [trainer.py] => prefix: reproduce_debug\n",
            "2025-12-04 09:26:42,044 [trainer.py] => dataset: cifar100\n",
            "2025-12-04 09:26:42,044 [trainer.py] => data_path: data/\n",
            "2025-12-04 09:26:42,044 [trainer.py] => memory_size: 0\n",
            "2025-12-04 09:26:42,044 [trainer.py] => memory_per_class: 0\n",
            "2025-12-04 09:26:42,044 [trainer.py] => fixed_memory: True\n",
            "2025-12-04 09:26:42,044 [trainer.py] => shuffle: False\n",
            "2025-12-04 09:26:42,044 [trainer.py] => init_cls: 10\n",
            "2025-12-04 09:26:42,045 [trainer.py] => increment: 10\n",
            "2025-12-04 09:26:42,045 [trainer.py] => total_sessions: 2\n",
            "2025-12-04 09:26:42,045 [trainer.py] => model_name: InfLoRA\n",
            "2025-12-04 09:26:42,045 [trainer.py] => net_type: sip\n",
            "2025-12-04 09:26:42,045 [trainer.py] => embd_dim: 768\n",
            "2025-12-04 09:26:42,045 [trainer.py] => num_heads: 12\n",
            "2025-12-04 09:26:42,045 [trainer.py] => seed: 0\n",
            "2025-12-04 09:26:42,045 [trainer.py] => EPSILON: 1e-08\n",
            "2025-12-04 09:26:42,045 [trainer.py] => init_epoch: 2\n",
            "2025-12-04 09:26:42,045 [trainer.py] => optim: adam\n",
            "2025-12-04 09:26:42,045 [trainer.py] => init_lr: 0.0005\n",
            "2025-12-04 09:26:42,045 [trainer.py] => init_lr_decay: 0.1\n",
            "2025-12-04 09:26:42,045 [trainer.py] => init_weight_decay: 0.0\n",
            "2025-12-04 09:26:42,045 [trainer.py] => epochs: 2\n",
            "2025-12-04 09:26:42,045 [trainer.py] => lrate: 0.0005\n",
            "2025-12-04 09:26:42,045 [trainer.py] => lrate_decay: 0.1\n",
            "2025-12-04 09:26:42,045 [trainer.py] => batch_size: 32\n",
            "2025-12-04 09:26:42,045 [trainer.py] => weight_decay: 0.0\n",
            "2025-12-04 09:26:42,046 [trainer.py] => rank: 4\n",
            "2025-12-04 09:26:42,046 [trainer.py] => lamb: 0.95\n",
            "2025-12-04 09:26:42,046 [trainer.py] => lame: 1.0\n",
            "2025-12-04 09:26:42,046 [trainer.py] => num_workers: 2\n",
            "2025-12-04 09:26:43,939 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "2025-12-04 09:26:46,338 [trainer.py] => All params: 107680123\n",
            "2025-12-04 09:26:46,339 [trainer.py] => Trainable params: 107680123\n",
            "2025-12-04 09:26:46,339 [inflora.py] => Learning on 0-10\n",
            "Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight'}\n",
            "Task 0, Epoch 2/2 => Loss 0.190, Train_accy 93.76: 100% 2/2 [05:09<00:00, 154.59s/it]\n",
            "2025-12-04 09:33:12,885 [inflora.py] => Task 0, Epoch 2/2 => Loss 0.190, Train_accy 93.76\n",
            "Threshold:  0.95\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 6/768 type remove\n",
            "Layer 2 : 9/768 type remove\n",
            "Layer 3 : 11/768 type remove\n",
            "Layer 4 : 10/768 type remove\n",
            "Layer 5 : 11/768 type remove\n",
            "Layer 6 : 13/768 type remove\n",
            "Layer 7 : 12/768 type remove\n",
            "Layer 8 : 16/768 type remove\n",
            "Layer 9 : 17/768 type remove\n",
            "Layer 10 : 14/768 type remove\n",
            "Layer 11 : 5/768 type remove\n",
            "Layer 12 : 9/768 type remove\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 6 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 7 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 8 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 9 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 10 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 11 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 12 - Projection Matrix shape: torch.Size([768, 768])\n",
            "2025-12-04 09:35:43,455 [trainer.py] => Time:537.115594625473\n",
            "1000 1000\n",
            "1000 1000\n",
            "2025-12-04 09:35:58,328 [trainer.py] => Time:14.871159315109253\n",
            "2025-12-04 09:35:58,328 [inflora.py] => Exemplar size: 0\n",
            "2025-12-04 09:35:58,328 [trainer.py] => CNN: {'total': np.float64(98.9), '00-09': np.float64(98.9), 'old': 0, 'new': np.float64(98.9)}\n",
            "2025-12-04 09:35:58,328 [trainer.py] => CNN top1 curve: [np.float64(98.9)]\n",
            "2025-12-04 09:35:58,328 [trainer.py] => CNN top1 with task curve: [np.float64(98.9)]\n",
            "2025-12-04 09:35:58,328 [trainer.py] => CNN top1 task curve: [1.0]\n",
            "2025-12-04 09:35:59,538 [trainer.py] => All params: 107680123\n",
            "2025-12-04 09:35:59,539 [trainer.py] => Trainable params: 81418\n",
            "2025-12-04 09:35:59,539 [inflora.py] => Learning on 10-20\n",
            "Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_v.1.weight', 'image_encoder.blocks.11.attn.lora_B_k.1.weight', 'image_encoder.blocks.10.attn.lora_B_v.1.weight', 'image_encoder.blocks.4.attn.lora_B_k.1.weight', 'image_encoder.blocks.11.attn.lora_B_v.1.weight', 'image_encoder.blocks.9.attn.lora_B_v.1.weight', 'classifier_pool.1.weight', 'image_encoder.blocks.7.attn.lora_B_k.1.weight', 'classifier_pool.1.bias', 'image_encoder.blocks.6.attn.lora_B_k.1.weight', 'image_encoder.blocks.6.attn.lora_B_v.1.weight', 'image_encoder.blocks.0.attn.lora_B_v.1.weight', 'image_encoder.blocks.7.attn.lora_B_v.1.weight', 'image_encoder.blocks.8.attn.lora_B_k.1.weight', 'image_encoder.blocks.5.attn.lora_B_v.1.weight', 'image_encoder.blocks.8.attn.lora_B_v.1.weight', 'image_encoder.blocks.3.attn.lora_B_v.1.weight', 'image_encoder.blocks.10.attn.lora_B_k.1.weight', 'image_encoder.blocks.1.attn.lora_B_k.1.weight', 'image_encoder.blocks.2.attn.lora_B_v.1.weight', 'image_encoder.blocks.1.attn.lora_B_v.1.weight', 'image_encoder.blocks.0.attn.lora_B_k.1.weight', 'image_encoder.blocks.9.attn.lora_B_k.1.weight', 'image_encoder.blocks.2.attn.lora_B_k.1.weight', 'image_encoder.blocks.5.attn.lora_B_k.1.weight', 'image_encoder.blocks.3.attn.lora_B_k.1.weight'}\n",
            "Task 1, Epoch 2/2 => Loss 0.235, Train_accy 92.28: 100% 2/2 [05:10<00:00, 155.05s/it]\n",
            "2025-12-04 09:42:28,903 [inflora.py] => Task 1, Epoch 2/2 => Loss 0.235, Train_accy 92.28\n",
            "Threshold:  0.975\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 7/768 type remove\n",
            "Layer 2 : 12/768 type remove\n",
            "Layer 3 : 16/768 type remove\n",
            "Layer 4 : 17/768 type remove\n",
            "Layer 5 : 24/768 type remove\n",
            "Layer 6 : 31/768 type remove\n",
            "Layer 7 : 32/768 type remove\n",
            "Layer 8 : 45/768 type remove\n",
            "Layer 9 : 56/768 type remove\n",
            "Layer 10 : 56/768 type remove\n",
            "Layer 11 : 20/768 type remove\n",
            "Layer 12 : 32/768 type remove\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 6 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 7 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 8 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 9 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 10 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 11 - Projection Matrix shape: torch.Size([768, 768])\n",
            "Layer 12 - Projection Matrix shape: torch.Size([768, 768])\n",
            "2025-12-04 09:45:00,717 [trainer.py] => Time:541.1781208515167\n",
            "2000 2000\n",
            "2000 2000\n",
            "2025-12-04 09:45:30,166 [trainer.py] => Time:29.446051359176636\n",
            "2025-12-04 09:45:30,166 [inflora.py] => Exemplar size: 0\n",
            "2025-12-04 09:45:30,166 [trainer.py] => CNN: {'total': np.float64(95.4), '00-09': np.float64(94.2), '10-19': np.float64(96.6), 'old': np.float64(94.2), 'new': np.float64(96.6)}\n",
            "2025-12-04 09:45:30,166 [trainer.py] => CNN top1 curve: [np.float64(98.9), np.float64(95.4)]\n",
            "2025-12-04 09:45:30,166 [trainer.py] => CNN top1 with task curve: [np.float64(98.9), np.float64(98.8)]\n",
            "2025-12-04 09:45:30,166 [trainer.py] => CNN top1 task curve: [1.0, 0.964]\n",
            "2025-12-04 09:45:31,301 [trainer.py] => All params: 107680123\n",
            "2025-12-04 09:45:31,302 [trainer.py] => Trainable params: 81418\n",
            "2025-12-04 09:45:31,303 [inflora.py] => Learning on 20-30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/InfLoRA/main.py\", line 33, in <module>\n",
            "    main()\n",
            "  File \"/content/InfLoRA/main.py\", line 11, in main\n",
            "    train(args)\n",
            "  File \"/content/InfLoRA/trainer.py\", line 21, in train\n",
            "    _train(args)\n",
            "  File \"/content/InfLoRA/trainer.py\", line 62, in _train\n",
            "    model.incremental_train(data_manager)\n",
            "  File \"/content/InfLoRA/methods/inflora.py\", line 125, in incremental_train\n",
            "    self._train(self.train_loader, self.test_loader)\n",
            "  File \"/content/InfLoRA/methods/inflora.py\", line 161, in _train\n",
            "    self._network(inputs, get_cur_feat=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/InfLoRA/models/sinet_inflora.py\", line 110, in forward\n",
            "    image_features, prompt_loss = self.image_encoder(image, task_id=self.numtask-1, get_feat=get_feat, get_cur_feat=get_cur_feat)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/InfLoRA/models/sinet_inflora.py\", line 30, in forward\n",
            "    x = blk(x, task_id, register_blk==i, get_feat=get_feat, get_cur_feat=get_cur_feat)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/InfLoRA/models/vit_inflora.py\", line 304, in forward\n",
            "    x = x + self.drop_path1(self.ls1(self.attn(self.norm1(x), task, register_hook=register_hook, get_feat=get_feat, get_cur_feat=get_cur_feat)))\n",
            "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/InfLoRA/models/vit_inflora.py\", line 246, in forward\n",
            "    weight_k = torch.stack([torch.mm(self.lora_B_k[t].weight, self.lora_A_k[t].weight) for t in range(task+1)], dim=0).sum(dim=0)\n",
            "                                     ~~~~~~~~~~~~~^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 383, in __getitem__\n",
            "    return self._modules[self._get_abs_string_index(idx)]\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 367, in _get_abs_string_index\n",
            "    raise IndexError(f\"index {idx} is out of range\")\n",
            "IndexError: index 2 is out of range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR6N-KZOrb1Y",
        "outputId": "2988b02d-b8b2-4098-b826-6dadbb61f170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        }
      ]
    }
  ]
}